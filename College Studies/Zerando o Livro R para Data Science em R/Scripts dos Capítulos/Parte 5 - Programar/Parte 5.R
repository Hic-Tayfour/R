#----Cap√≠tulo 25 : Fun√ß√µes----

#----25.1 Introdu√ß√£o----
"
Uma das melhores maneiras de melhorar seu alcance como cientista de dados √© escrever fun√ß√µes. Fun√ß√µes permitem que voc√™ automatize tarefas comuns de uma maneira mais poderosa e geral do que copiar e colar. Escrever uma fun√ß√£o tem quatro grandes vantagens sobre o uso de c√≥pia e cola:
"
#1¬∫ Voc√™ pode dar um nome sugestivo √† fun√ß√£o que torna seu c√≥digo mais f√°cil de entender.
#2¬∫ √Ä medida que os requisitos mudam, voc√™ s√≥ precisa atualizar o c√≥digo em um lugar, em vez de v√°rios.
#3¬∫ Voc√™ elimina a chance de cometer erros incidentais ao copiar e colar (por exemplo, atualizar um nome de vari√°vel em um lugar, mas n√£o em outro).
#4¬∫ Facilita a reutiliza√ß√£o do trabalho de projeto para projeto, aumentando sua produtividade ao longo do tempo.

"
Uma boa regra √© considerar escrever uma fun√ß√£o sempre que voc√™ copiou e colou um bloco de c√≥digo mais de duas vezes (ou seja, voc√™ agora tem tr√™s c√≥pias do mesmo c√≥digo). Neste cap√≠tulo, voc√™ aprender√° sobre tr√™s tipos √∫teis de fun√ß√µes:
"
#1¬∫ Fun√ß√µes vetoriais recebem um ou mais vetores como entrada e retornam um vetor como sa√≠da.
#2¬∫ Fun√ß√µes de data frame recebem um data frame como entrada e retornam um data frame como sa√≠da.
#3¬∫ Fun√ß√µes de plotagem que recebem um data frame como entrada e retornam um gr√°fico como sa√≠da.


"
Os t√≥picos mais afrente incluem muitos exemplos para ajud√°-lo a generalizar os padr√µes que voc√™ v√™.
"

#----25.1.1 Pr√©-requisitos----
"
N√≥s concluiremos uma variedade de fun√ß√µes de diferentes partes do tidyverse. Tamb√©m usaremos nycflights13 como uma fonte de dados familiares para aplicar nossas fun√ß√µes.
"
library(tidyverse)
library(nycflights13)

#----25.2 Fun√ß√µes Vetoriais----
"
Come√ßaremos com fun√ß√µes vetoriais: fun√ß√µes que recebem um ou mais vetores e retornam um resultado vetorial. Por exemplo, d√™ uma olhada neste c√≥digo. O que ele faz?
"
df <- tibble(
  a = rnorm(5),
  b = rnorm(5),
  c = rnorm(5),
  d = rnorm(5),
)

df |> mutate(
  a = (a - min(a, na.rm = TRUE)) / 
    (max(a, na.rm = TRUE) - min(a, na.rm = TRUE)),
  b = (b - min(b, na.rm = TRUE)) / 
    (max(b, na.rm = TRUE) - min(a, na.rm = TRUE)),
  c = (c - min(c, na.rm = TRUE)) / 
    (max(c, na.rm = TRUE) - min(c, na.rm = TRUE)),
  d = (d - min(d, na.rm = TRUE)) / 
    (max(d, na.rm = TRUE) - min(d, na.rm = TRUE)),
)

"
Voc√™ pode ser capaz de deduzir que este c√≥digo redimensiona cada coluna para ter uma escala de 0 a 1. Mas voc√™ percebeu o erro? Quando Hadley escreveu este c√≥digo, ele cometeu um erro ao copiar e colar e esqueceu de mudar um 'a' para um 'b'. Prevenir esse tipo de erro √© um motivo muito bom para aprender a escrever fun√ß√µes.
"

#----25.2.1 Escrevendo uma Fun√ß√£o----
"
Para escrever uma fun√ß√£o, voc√™ precisa primeiro analisar seu c√≥digo repetido para descobrir quais partes s√£o constantes e quais partes variam. Se pegarmos o c√≥digo acima e retir√°-lo de dentro de mutate(), fica um pouco mais f√°cil ver o padr√£o, pois cada repeti√ß√£o agora est√° em uma linha:
"
(a - min(a, na.rm = TRUE)) / (max(a, na.rm = TRUE) - min(a, na.rm = TRUE))
(b - min(b, na.rm = TRUE)) / (max(b, na.rm = TRUE) - min(b, na.rm = TRUE))
(c - min(c, na.rm = TRUE)) / (max(c, na.rm = TRUE) - min(c, na.rm = TRUE))
(d - min(d, na.rm = TRUE)) / (max(d, na.rm = TRUE) - min(d, na.rm = TRUE))  
"
Para tornar isso um pouco mais claro, podemos substituir a parte que varia por ‚ñà:
"
#(‚ñà - min(‚ñà, na.rm = TRUE)) / (max(‚ñà, na.rm = TRUE) - min(‚ñà, na.rm = TRUE))

"
Para transformar isso em uma fun√ß√£o, voc√™ precisa de tr√™s coisas:
"

#1¬∫ Um nome. Aqui usaremos rescale01, pois esta fun√ß√£o redimensiona um vetor para ficar entre 0 e 1.
#2¬∫ Os argumentos. Os argumentos s√£o coisas que variam entre as chamadas, e nossa an√°lise acima nos diz que temos apenas um. Chamaremos isso de x, pois este √© o nome convencional para um vetor num√©rico.
#3¬∫ O corpo. O corpo √© o c√≥digo que √© repetido em todas as chamadas.
"
Ent√£o voc√™ cria uma fun√ß√£o seguindo o modelo:

name <- function(arguments) {
  body
}

Para este caso, isso leva a:
"
rescale01 <- function(x) {
  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}

"
Neste ponto, voc√™ pode testar com algumas entradas simples para garantir que capturou a l√≥gica corretamente:
"
rescale01(c(-10, 0, 10))
rescale01(c(1, 2, 3, NA, 5))

"
Ent√£o, voc√™ pode reescrever a chamada para mutate() como:
"
df |> mutate(
  a = rescale01(a),
  b = rescale01(b),
  c = rescale01(c),
  d = rescale01(d),
)

"
Futuramente, voc√™ aprender√° a usar across() para reduzir ainda mais a duplica√ß√£o, de modo que tudo o que voc√™ precisa √© df |> mutate(across(a:d, rescale01))
"

#----25.2.2 Melhorando Nossa Fun√ß√£o----
"
Voc√™ pode notar que a fun√ß√£o rescale01() faz um trabalho desnecess√°rio ‚Äî em vez de calcular min() duas vezes e max() uma vez, poder√≠amos calcular o m√≠nimo e o m√°ximo em uma etapa com range():
"
rescale01 <- function(x) {
  rng <- range(x, na.rm = TRUE)
  (x - rng[1]) / (rng[2] - rng[1])
}

"
Ou voc√™ pode tentar essa fun√ß√£o em um vetor que inclui um valor infinito:
"
x <- c(1:10, Inf)
rescale01(x)

"
Esse resultado n√£o √© particularmente √∫til, ent√£o poder√≠amos pedir para range() ignorar valores infinitos:
"
rescale01 <- function(x) {
  rng <- range(x, na.rm = TRUE, finite = TRUE)
  (x - rng[1]) / (rng[2] - rng[1])
}

rescale01(x)

"
Essas mudan√ßas ilustram um benef√≠cio importante das fun√ß√µes: como movemos o c√≥digo repetido para uma fun√ß√£o, s√≥ precisamos fazer a mudan√ßa em um lugar.
"

#----25.2.3 Fun√ß√µes de Muta√ß√£o----
"
Agora que voc√™ entendeu a ideia b√°sica das fun√ß√µes, vamos dar uma olhada em v√°rios exemplos. Come√ßaremos analisando as fun√ß√µes 'mutate', ou seja, fun√ß√µes que funcionam bem dentro de mutate() e filter() porque retornam uma sa√≠da do mesmo comprimento que a entrada.

Vamos come√ßar com uma varia√ß√£o simples de rescale01(). Talvez voc√™ queira calcular o escore Z, redimensionando um vetor para ter uma m√©dia de zero e um desvio padr√£o de um:
"
z_score <- function(x) {
  (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)
}

"
Ou talvez voc√™ queira encapsular um caso simples de case_when() e dar a ele um nome √∫til. Por exemplo, esta fun√ß√£o clamp() garante que todos os valores de um vetor estejam entre um m√≠nimo ou um m√°ximo:
"
clamp <- function(x, min, max) {
  case_when(
    x < min ~ min,
    x > max ~ max,
    .default = x
  )
}

clamp(1:10, min = 3, max = 7)

"
Claro que as fun√ß√µes n√£o precisam trabalhar apenas com vari√°veis num√©ricas. Voc√™ pode querer fazer alguma manipula√ß√£o de string repetida. Talvez voc√™ precise tornar a primeira letra mai√∫scula:
"
first_upper <- function(x) {
  str_sub(x, 1, 1) <- str_to_upper(str_sub(x, 1, 1))
  x
}

first_upper("hello")

"
Ou talvez voc√™ queira remover sinais de porcentagem, v√≠rgulas e cifr√µes de uma string antes de convert√™-la em um n√∫mero:
"
clean_number <- function(x) {
  is_pct <- str_detect(x, "%")
  num <- x |> 
    str_remove_all("%") |> 
    str_remove_all(",") |> 
    str_remove_all(fixed("$")) |> 
    as.numeric()
  if_else(is_pct, num / 100, num)
}

clean_number("$12,300")
clean_number("45%")

"
√Äs vezes, suas fun√ß√µes ser√£o altamente especializadas para uma etapa de an√°lise de dados. Por exemplo, se voc√™ tem um monte de vari√°veis que registram valores ausentes como 997, 998 ou 999, voc√™ pode querer escrever uma fun√ß√£o para substitu√≠-los por NA:
"
fix_na <- function(x) {
  if_else(x %in% c(997, 998, 999), NA, x)
}

"
N√≥s nos concentramos em exemplos que pegam um √∫nico vetor porque achamos que s√£o os mais comuns. Mas n√£o h√° raz√£o para que sua fun√ß√£o n√£o possa receber m√∫ltiplas entradas vetoriais.
"

#----25.2.4 Fun√ß√µes de Resumo----
"
Outra fam√≠lia importante de fun√ß√µes vetoriais s√£o as fun√ß√µes de resumo, que retornam um √∫nico valor para uso em summarize(). √Äs vezes, isso pode ser apenas uma quest√£o de definir um ou dois argumentos padr√£o:
"
commas <- function(x) {
  str_flatten(x, collapse = ", ", last = " and ")
}

commas(c("cat", "dog", "pigeon"))

"
Ou voc√™ pode encapsular um c√°lculo simples, como para o coeficiente de varia√ß√£o, que divide o desvio padr√£o pela m√©dia:
"
cv <- function(x, na.rm = FALSE) {
  sd(x, na.rm = na.rm) / mean(x, na.rm = na.rm)
}

cv(runif(100, min = 0, max = 50))
cv(runif(100, min = 0, max = 500))

"
Ou talvez voc√™ queira tornar um padr√£o comum mais f√°cil de lembrar, dando a ele um nome memor√°vel:
"
n_missing <- function(x) {
  sum(is.na(x))
} 

"
Voc√™ tamb√©m pode escrever fun√ß√µes com m√∫ltiplas entradas vetoriais. Por exemplo, talvez voc√™ queira calcular o erro percentual m√©dio absoluto para ajud√°-lo a comparar previs√µes de modelos com valores reais:
"
mape <- function(actual, predicted) {
  sum(abs((actual - predicted) / actual)) / length(actual)
}

"
RStudio
Uma vez que voc√™ come√ßa a escrever fun√ß√µes, existem dois atalhos no RStudio que s√£o super √∫teis:

  # Para encontrar a defini√ß√£o de uma fun√ß√£o que voc√™ escreveu, coloque o cursor sobre o nome da fun√ß√£o e pressione F2.

  # Para acessar rapidamente uma fun√ß√£o, pressione 'Ctrl + .' para abrir o localizador de arquivos e fun√ß√µes e digite as primeiras letras do nome da sua fun√ß√£o. Voc√™ tamb√©m pode navegar at√© arquivos, se√ß√µes do Quarto e mais, tornando-o uma ferramenta de navega√ß√£o muito √∫til.
"


#----25.3 Fun√ß√µes de DataFrames----
"
Fun√ß√µes vetoriais s√£o √∫teis para extrair c√≥digo que √© repetido dentro de um verbo dplyr. Mas voc√™ tamb√©m frequentemente repetir√° os pr√≥prios verbos, especialmente dentro de um grande pipeline. Quando voc√™ se pegar copiando e colando m√∫ltiplos verbos v√°rias vezes, voc√™ pode pensar em escrever uma fun√ß√£o de data frame. Fun√ß√µes de data frame funcionam como verbos dplyr: elas tomam um data frame como primeiro argumento, alguns argumentos extras que dizem o que fazer com ele e retornam um data frame ou um vetor.

Para permitir que voc√™ escreva uma fun√ß√£o que usa verbos dplyr, primeiro vamos introduzi-lo ao desafio da indire√ß√£o e como voc√™ pode super√°-lo com o conceito de 'embracing', {{ }}. Com essa teoria em mente, ent√£o mostraremos uma s√©rie de exemplos para ilustrar o que voc√™ pode fazer com isso.
"


#----25.3.1 Indire√ß√£o e Avalia√ß√£o Tidy----
"
Quando voc√™ come√ßa a escrever fun√ß√µes que usam fun√ß√µes dplyr, rapidamente se depara com o problema da indire√ß√£o. Vamos ilustrar o problema com uma fun√ß√£o muito simples: grouped_mean(). O objetivo desta fun√ß√£o √© calcular a m√©dia de mean_var agrupada por group_var:
"
grouped_mean <- function(df, group_var, mean_var) {
  df |> 
    group_by(group_var) |> 
    summarize(mean(mean_var))
}

"
Se tentarmos us√°-la, recebemos um erro:
"
diamonds |> grouped_mean(cut, carat)

"
Para tornar o problema um pouco mais claro, podemos usar um data frame fict√≠cio:
"
df <- tibble(
  mean_var = 1,
  group_var = "g",
  group = 1,
  x = 10,
  y = 100
)

df |> grouped_mean(group, x)
df |> grouped_mean(group, y)

"
Independentemente de como chamamos grouped_mean(), ela sempre executa df |> group_by(group_var) |> summarize(mean(mean_var)), em vez de df |> group_by(group) |> summarize(mean(x)) ou df |> group_by(group) |> summarize(mean(y)). Este √© um problema de indire√ß√£o e surge porque o dplyr usa avalia√ß√£o arrumada (tidy evaluation) para permitir que voc√™ se refira aos nomes das vari√°veis dentro do seu data frame sem nenhum tratamento especial.

A avalia√ß√£o arrumada √© √≥tima 95% do tempo porque torna suas an√°lises de dados muito concisas, pois voc√™ nunca precisa dizer de qual data frame uma vari√°vel vem; isso √© √≥bvio pelo contexto. A desvantagem da avalia√ß√£o arrumada surge quando queremos encapsular c√≥digo repetido do tidyverse em uma fun√ß√£o. Aqui precisamos de alguma forma de dizer a group_by() e summarize() para n√£o tratar group_var e mean_var como o nome das vari√°veis, mas sim olhar dentro delas para a vari√°vel que realmente queremos usar.

A avalia√ß√£o arrumada inclui uma solu√ß√£o para esse problema chamada 'embracing' ü§ó. Abra√ßar uma vari√°vel significa envolv√™-la em chaves, ent√£o (por exemplo) var se torna {{ var }}. Abra√ßar uma vari√°vel diz ao dplyr para usar o valor armazenado dentro do argumento, n√£o o argumento como o nome literal da vari√°vel. Uma maneira de lembrar o que est√° acontecendo √© pensar em {{ }} como olhando por um t√∫nel ‚Äî {{ var }} far√° uma fun√ß√£o dplyr olhar dentro de var em vez de procurar uma vari√°vel chamada var.

Ent√£o, para fazer grouped_mean() funcionar, precisamos cercar group_var e mean_var com {{ }}:
"
grouped_mean <- function(df, group_var, mean_var) {
  df |> 
    group_by({{ group_var }}) |> 
    summarize(mean({{ mean_var }}))
}

df |> grouped_mean(group, x)

"
Sucesso!
"

#----25.3.2 Quando Abra√ßar?----
"
Portanto, o principal desafio ao escrever fun√ß√µes de data frame √© descobrir quais argumentos precisam ser 'embraced' (abra√ßados). Felizmente, isso √© f√°cil porque voc√™ pode consultar a documenta√ß√£o üòÑ. H√° dois termos para procurar nos documentos que correspondem aos dois subtipos mais comuns de avalia√ß√£o arrumada (tidy evaluation):
"
#1¬∫ Data-masking (mascaramento de dados): √© usado em fun√ß√µes como arrange(), filter() e summarize() que calculam com vari√°veis.
#2¬∫ Data-masking (mascaramento de dados): √© usado em fun√ß√µes como arrange(), filter() e summarize() que calculam com vari√°veis.

"
Sua intui√ß√£o sobre quais argumentos usam avalia√ß√£o arrumada deve ser boa para muitas fun√ß√µes comuns ‚Äî basta pensar se voc√™ pode calcular (por exemplo, x + 1) ou selecionar (por exemplo, a:x).

Nas pr√≥ximas se√ß√µes, exploraremos os tipos de fun√ß√µes √∫teis que voc√™ pode escrever uma vez que entenda o conceito de 'embracing'.
"

#----25.3.3 Casos de Uso Comuns----
"
Se voc√™ comumente realiza o mesmo conjunto de resumos ao fazer a explora√ß√£o inicial de dados, pode considerar agrup√°-los em uma fun√ß√£o auxiliar:
"
summary6 <- function(data, var) {
  data |> summarize(
    min = min({{ var }}, na.rm = TRUE),
    mean = mean({{ var }}, na.rm = TRUE),
    median = median({{ var }}, na.rm = TRUE),
    max = max({{ var }}, na.rm = TRUE),
    n = n(),
    n_miss = sum(is.na({{ var }})),
    .groups = "drop"
  )
}

diamonds |> summary6(carat)

"
Sempre que voc√™ encapsula summarize() em um auxiliar, achamos que √© uma boa pr√°tica definir .groups = 'drop' para evitar a mensagem e deixar os dados em um estado n√£o agrupado.

O bom dessa fun√ß√£o √© que, como ela encapsula summarize(), voc√™ pode us√°-la em dados agrupados:
"
diamonds |> 
  group_by(cut) |> 
  summary6(carat)

"
Al√©m disso, como os argumentos para summarize s√£o de mascaramento de dados, isso tamb√©m significa que o argumento var para summary6() √© de mascaramento de dados. Isso significa que voc√™ tamb√©m pode resumir vari√°veis calculadas:
"
diamonds |> 
  group_by(cut) |> 
  summary6(log10(carat))

"
Para resumir m√∫ltiplas vari√°veis, voc√™ precisar√° esperar um pouco, onde aprender√° a usar across().

Outra fun√ß√£o auxiliar popular de summarize() √© uma vers√£o de count() que tamb√©m calcula propor√ß√µes:
"
count_prop <- function(df, var, sort = FALSE) {
  df |>
    count({{ var }}, sort = sort) |>
    mutate(prop = n / sum(n))
}

diamonds |> count_prop(clarity)

"
Esta fun√ß√£o tem tr√™s argumentos: df, var e sort, e apenas var precisa ser abra√ßado porque √© passado para count(), que usa mascaramento de dados para todas as vari√°veis. Observe que usamos um valor padr√£o para sort, de modo que, se o usu√°rio n√£o fornecer seu pr√≥prio valor, ele ser√° definido como FALSE por padr√£o.

Ou talvez voc√™ queira encontrar os valores √∫nicos ordenados de uma vari√°vel para um subconjunto dos dados. Em vez de fornecer uma vari√°vel e um valor para fazer o filtro, permitiremos que o usu√°rio forne√ßa uma condi√ß√£o:
"
unique_where <- function(df, condition, var) {
  df |> 
    filter({{ condition }}) |> 
    distinct({{ var }}) |> 
    arrange({{ var }})
}

# Encontre todos os destinos em dezembro.
flights |> unique_where(month == 12, dest)

"
Aqui abra√ßamos condition porque √© passado para filter() e var porque √© passado para distinct() e arrange().

Fizemos todos esses exemplos para receber um data frame como primeiro argumento, mas se voc√™ est√° trabalhando repetidamente com os mesmos dados, pode fazer sentido codific√°-los diretamente. Por exemplo, a fun√ß√£o a seguir sempre trabalha com o conjunto de dados flights e sempre seleciona time_hour, carrier e flight, j√° que eles formam a chave prim√°ria composta que permite identificar uma linha.
"
subset_flights <- function(rows, cols) {
  flights |> 
    filter({{ rows }}) |> 
    select(time_hour, carrier, flight, {{ cols }})
}

#----25.3.4 Mascaramento de Dados vs. Sele√ß√£o Tidy----
"
√Äs vezes voc√™ quer selecionar vari√°veis dentro de uma fun√ß√£o que usa mascaramento de dados. Por exemplo, imagine que voc√™ quer escrever uma count_missing() que conta o n√∫mero de observa√ß√µes ausentes em linhas. Voc√™ pode tentar escrever algo como:
"
count_missing <- function(df, group_vars, x_var) {
  df |> 
    group_by({{ group_vars }}) |> 
    summarize(
      n_miss = sum(is.na({{ x_var }})),
      .groups = "drop"
    )
}

flights |> 
  count_missing(c(year, month, day), dep_time)

"
Isso n√£o funciona porque group_by() usa mascaramento de dados, n√£o sele√ß√£o arrumada. Podemos contornar esse problema usando a fun√ß√£o √∫til pick(), que permite usar sele√ß√£o arrumada dentro de fun√ß√µes de mascaramento de dados:
"
count_missing <- function(df, group_vars, x_var) {
  df |> 
    group_by(pick({{ group_vars }})) |> 
    summarize(
      n_miss = sum(is.na({{ x_var }})),
      .groups = "drop"
    )
}

flights |> 
  count_missing(c(year, month, day), dep_time)

"
Outro uso conveniente de pick() √© fazer uma tabela 2D de contagens. Aqui contamos usando todas as vari√°veis nas linhas e colunas, e depois usamos pivot_wider() para rearranjar as contagens em uma grade:
"
count_wide <- function(data, rows, cols) {
  data |> 
    count(pick(c({{ rows }}, {{ cols }}))) |> 
    pivot_wider(
      names_from = {{ cols }}, 
      values_from = n,
      names_sort = TRUE,
      values_fill = 0
    )
}

diamonds |> count_wide(c(clarity, color), cut)

"
Embora nossos exemplos tenham se concentrado principalmente no dplyr, a avalia√ß√£o arrumada tamb√©m sustenta o tidyr, e se voc√™ olhar os documentos de pivot_wider() pode ver que names_from usa sele√ß√£o arrumada.
"

#----25.4 Fun√ß√µes de Gr√°ficos----
"
Em vez de retornar um data frame, voc√™ pode querer retornar um gr√°fico. Felizmente, voc√™ pode usar as mesmas t√©cnicas com o ggplot2, porque aes() √© uma fun√ß√£o de mascaramento de dados. Por exemplo, imagine que voc√™ est√° fazendo muitos histogramas:
"
diamonds |> 
  ggplot(aes(x = carat)) +
  geom_histogram(binwidth = 0.1)

diamonds |> 
  ggplot(aes(x = carat)) +
  geom_histogram(binwidth = 0.05)

"
N√£o seria bom se voc√™ pudesse encapsular isso em uma fun√ß√£o de histograma? Isso √© f√°cil como um passeio no parque uma vez que voc√™ sabe que aes() √© uma fun√ß√£o de mascaramento de dados e voc√™ precisa abra√ßar:
"
histogram <- function(df, var, binwidth = NULL) {
  df |> 
    ggplot(aes(x = {{ var }})) + 
    geom_histogram(binwidth = binwidth)
}

diamonds |> histogram(carat, 0.1)

"
Note que histogram() retorna um gr√°fico ggplot2, o que significa que voc√™ ainda pode adicionar componentes adicionais se quiser. Apenas lembre-se de trocar de |> para +:
"
diamonds |> 
  histogram(carat, 0.1) +
  labs(x = "Size (in carats)", y = "Number of diamonds")

#----25.4.1 Mais Vari√°veis----
"
√â simples adicionar mais vari√°veis √† mistura. Por exemplo, talvez voc√™ queira uma maneira f√°cil de avaliar visualmente se um conjunto de dados √© linear ou n√£o, sobrepondo uma linha suave e uma linha reta:
"
linearity_check <- function(df, x, y) {
  df |>
    ggplot(aes(x = {{ x }}, y = {{ y }})) +
    geom_point() +
    geom_smooth(method = "loess", formula = y ~ x, color = "red", se = FALSE) +
    geom_smooth(method = "lm", formula = y ~ x, color = "blue", se = FALSE) 
}

starwars |> 
  filter(mass < 1000) |> 
  linearity_check(mass, height)

"
Ou talvez voc√™ queira uma alternativa para gr√°ficos de dispers√£o coloridos para conjuntos de dados muito grandes onde a sobreposi√ß√£o √© um problema:
"
hex_plot <- function(df, x, y, z, bins = 20, fun = "mean") {
  df |> 
    ggplot(aes(x = {{ x }}, y = {{ y }}, z = {{ z }})) + 
    stat_summary_hex(
      aes(color = after_scale(fill)), # make border same color as fill
      bins = bins, 
      fun = fun,
    )
}

diamonds |> hex_plot(carat, price, depth)

#----25.4.2 Combinando com Outros Tidyverse----
"
Algumas das ajudas mais √∫teis combinam um pouco de manipula√ß√£o de dados com o ggplot2. Por exemplo, se voc√™ quiser fazer um gr√°fico de barras vertical onde automaticamente ordena as barras em ordem de frequ√™ncia usando fct_infreq(). Como o gr√°fico de barras √© vertical, tamb√©m precisamos reverter a ordem usual para obter os valores mais altos no topo:
"
sorted_bars <- function(df, var) {
  df |> 
    mutate({{ var }} := fct_rev(fct_infreq({{ var }})))  |>
    ggplot(aes(y = {{ var }})) +
    geom_bar()
}

diamonds |> sorted_bars(clarity)

"
Temos que usar um novo operador aqui, := (comumente referido como o 'operador morsa'), porque estamos gerando o nome da vari√°vel com base em dados fornecidos pelo usu√°rio. Nomes de vari√°veis v√£o √† esquerda do =, mas a sintaxe do R n√£o permite nada √† esquerda do =, exceto por um √∫nico nome literal. Para contornar esse problema, usamos o operador especial := que a avalia√ß√£o arrumada trata exatamente da mesma maneira que =.

Ou talvez voc√™ queira facilitar o desenho de um gr√°fico de barras apenas para um subconjunto dos dados:
"
conditional_bars <- function(df, condition, var) {
  df |> 
    filter({{ condition }}) |> 
    ggplot(aes(x = {{ var }})) + 
    geom_bar()
}

diamonds |> conditional_bars(cut == "Good", clarity)

"
Voc√™ tamb√©m pode ser criativo e exibir resumos de dados de outras maneiras. Voc√™ pode encontrar uma aplica√ß√£o legal em 
https://gist.github.com/GShotwell/b19ef520b6d56f61a830fabb3454965b; ela usa os r√≥tulos dos eixos para exibir o valor mais alto. √Ä medida que voc√™ aprende mais sobre o ggplot2, o poder das suas fun√ß√µes continuar√° aumentando.

Vamos terminar com um caso mais complicado: rotulando os gr√°ficos que voc√™ cria.
"

#----25.4.3 Rotulagem----
"
Lembra da fun√ß√£o de histograma que mostramos anteriormente?
"
histogram <- function(df, var, binwidth = NULL) {
  df |> 
    ggplot(aes(x = {{ var }})) + 
    geom_histogram(binwidth = binwidth)
}

"
N√£o seria bom se pud√©ssemos rotular a sa√≠da com a vari√°vel e a largura do intervalo que foi usada? Para fazer isso, vamos ter que explorar os bastidores da avalia√ß√£o arrumada e usar uma fun√ß√£o de um pacote sobre o qual ainda n√£o falamos: rlang. Rlang √© um pacote de baixo n√≠vel que √© usado por praticamente todos os outros pacotes no tidyverse porque implementa a avalia√ß√£o arrumada (al√©m de muitas outras ferramentas √∫teis).

Para resolver o problema de rotulagem, podemos usar rlang::englue(). Isso funciona de maneira semelhante a str_glue(), ent√£o qualquer valor envolvido em {} ser√° inserido na string. Mas ele tamb√©m entende {{}}, que automaticamente insere o nome da vari√°vel apropriado:
"
histogram <- function(df, var, binwidth) {
  label <- rlang::englue("A histogram of {{var}} with binwidth {binwidth}")
  
  df |> 
    ggplot(aes(x = {{ var }})) + 
    geom_histogram(binwidth = binwidth) + 
    labs(title = label)
}

diamonds |> histogram(carat, 0.1)

"
Voc√™ pode usar a mesma abordagem em qualquer outro lugar onde deseja fornecer uma string em um gr√°fico ggplot2.
"

#----25.5 Estilo----
"
O R n√£o se importa com o nome da sua fun√ß√£o ou argumentos, mas os nomes fazem uma grande diferen√ßa para os humanos. Idealmente, o nome da sua fun√ß√£o ser√° curto, mas claramente evocar√° o que a fun√ß√£o faz. Isso √© dif√≠cil! Mas √© melhor ser claro do que curto, j√° que o autocomplete do RStudio facilita digitar nomes longos.

Geralmente, os nomes das fun√ß√µes devem ser verbos, e os argumentos devem ser substantivos. H√° algumas exce√ß√µes: substantivos s√£o aceit√°veis se a fun√ß√£o calcular um substantivo muito conhecido (ou seja, mean() √© melhor do que compute_mean()), ou acessar alguma propriedade de um objeto (ou seja, coef() √© melhor do que get_coefficients()). Use seu melhor julgamento e n√£o tenha medo de renomear uma fun√ß√£o se voc√™ descobrir um nome melhor mais tarde.
"
# Muito curta
f()

# Sem fun√ß√£o, ou descri√ß√£o
my_awesome_function()

# Longa, mas clara
impute_missing()
collapse_years()

"
O R tamb√©m n√£o se importa com a forma como voc√™ usa espa√ßos em branco em suas fun√ß√µes, mas os leitores futuros se importar√£o. Continue seguindo as regras vistas anteriormente. Al√©m disso, function() deve sempre ser seguido por chaves ({}), e o conte√∫do deve ser indentado por dois espa√ßos adicionais. Isso facilita ver a hierarquia no seu c√≥digo ao olhar rapidamente para a margem esquerda.
"
# Missing extra two spaces
density <- function(color, facets, binwidth = 0.1) {
  diamonds |> 
    ggplot(aes(x = carat, y = after_stat(density), color = {{ color }})) +
    geom_freqpoly(binwidth = binwidth) +
    facet_wrap(vars({{ facets }}))
}

# Pipe indented incorrectly
density <- function(color, facets, binwidth = 0.1) {
  diamonds |> 
    ggplot(aes(x = carat, y = after_stat(density), color = {{ color }})) +
    geom_freqpoly(binwidth = binwidth) +
    facet_wrap(vars({{ facets }}))
}

"
Como voc√™ pode ver, recomendamos colocar espa√ßos extras dentro de {{ }}. Isso torna muito √≥bvio que algo incomum est√° acontecendo.
"

#----Cap√≠tulo 26 : Itera√ß√£o----

#----26.1 Introdu√ß√£o----
"
Agora voc√™ aprender√° ferramentas para itera√ß√£o, realizando repetidamente a mesma a√ß√£o em diferentes objetos. A itera√ß√£o em R geralmente tende a parecer bastante diferente de outras linguagens de programa√ß√£o porque grande parte dela √© impl√≠cita e obtemos de gra√ßa. Por exemplo, se voc√™ quiser dobrar um vetor num√©rico x em R, voc√™ pode simplesmente escrever 2 * x. Na maioria das outras linguagens, voc√™ precisaria dobrar explicitamente cada elemento de x usando algum tipo de loop for.

Este livro j√° lhe deu um pequeno, mas poderoso n√∫mero de ferramentas que realizam a mesma a√ß√£o para m√∫ltiplas 'coisas':
"
#1¬∫ facet_wrap() e facet_grid() desenham um gr√°fico para cada subconjunto.
#2¬∫ group_by() mais summarize() calculam estat√≠sticas resumidas para cada subconjunto. 
#3¬∫ unnest_wider() e unnest_longer() criam novas linhas e colunas para cada elemento de uma coluna-lista.

"
Agora √© hora de aprender algumas ferramentas mais gerais, frequentemente chamadas de ferramentas de programa√ß√£o funcional, porque s√£o constru√≠das em torno de fun√ß√µes que recebem outras fun√ß√µes como entradas. Aprender programa√ß√£o funcional pode facilmente se desviar para o abstrato, mas neste cap√≠tulo manteremos as coisas concretas, focando em tr√™s tarefas comuns: modificar m√∫ltiplas colunas, ler m√∫ltiplos arquivos e salvar m√∫ltiplos objetos.
"

#----26.1.1 Pr√©-requisitos----
"
Aqui nos concentraremos em ferramentas fornecidas pelo dplyr e purrr, ambos membros centrais do tidyverse. Voc√™ j√° viu o dplyr antes, mas o purrr √© novidade. Vamos usar apenas algumas fun√ß√µes do purrr neste cap√≠tulo, mas √© um √≥timo pacote para explorar √† medida que voc√™ aprimora suas habilidades de programa√ß√£o.
"
library(tidyverse)

#----26.2 Modificando m√∫ltiplas colunas----
"
Imagine que voc√™ tem este simples tibble e quer contar o n√∫mero de observa√ß√µes e calcular a mediana de cada coluna.
"
df <- tibble(
  a = rnorm(10),
  b = rnorm(10),
  c = rnorm(10),
  d = rnorm(10)
)

"
Voc√™ poderia fazer isso com copiar e colar:
"
df |> summarize(
  n = n(),
  a = median(a),
  b = median(b),
  c = median(c),
  d = median(d),
)

"
Isso quebra nossa regra de nunca copiar e colar mais de duas vezes, e voc√™ pode imaginar que isso se tornar√° muito tedioso se voc√™ tiver dezenas ou at√© centenas de colunas. Em vez disso, voc√™ pode usar across():
"
df |> summarize(
  n = n(),
  across(a:d, median),
)

"
across() tem tr√™s argumentos particularmente importantes, que discutiremos em detalhes nas pr√≥ximas se√ß√µes. Voc√™ usar√° os dois primeiros sempre que usar across(): o primeiro argumento, .cols, especifica quais colunas voc√™ quer iterar, e o segundo argumento, .fns, especifica o que fazer com cada coluna. Voc√™ pode usar o argumento .names quando precisar de controle adicional sobre os nomes das colunas de sa√≠da, o que √© particularmente importante quando voc√™ usa across() com mutate(). Tamb√©m discutiremos duas varia√ß√µes importantes, if_any() e if_all(), que funcionam com filter().
"

#----26.2.1 Selecionando colunas com .cols----
"
O primeiro argumento para across(), .cols, seleciona as colunas a serem transformadas. Isso usa as mesmas especifica√ß√µes que select(), Se√ß√£o 3.3.2, ent√£o voc√™ pode usar fun√ß√µes como starts_with() e ends_with() para selecionar colunas baseadas em seus nomes.

H√° duas t√©cnicas adicionais de sele√ß√£o que s√£o particularmente √∫teis para across(): everything() e where(). everything() √© direto: seleciona todas as colunas (n√£o agrupadas):
"
df <- tibble(
  grp = sample(2, 10, replace = TRUE),
  a = rnorm(10),
  b = rnorm(10),
  c = rnorm(10),
  d = rnorm(10)
)

df |> 
  group_by(grp) |> 
  summarize(across(everything(), median))

"
Note que as colunas de agrupamento (grp aqui) n√£o s√£o inclu√≠das em across(), porque s√£o automaticamente preservadas por summarize().

where() permite que voc√™ selecione colunas baseadas em seu tipo:
"
#1¬∫ where(is.numeric) seleciona todas as colunas num√©ricas.
#2¬∫ where(is.character) seleciona todas as colunas de string.
#3¬∫ where(is.Date) seleciona todas as colunas de data.
#4¬∫ where(is.POSIXct) seleciona todas as colunas de data-hora.
#5¬∫ where(is.logical) seleciona todas as colunas l√≥gicas.

"
Assim como outros seletores, voc√™ pode combinar esses com √°lgebra booleana. Por exemplo, !where(is.numeric) seleciona todas as colunas n√£o num√©ricas, e starts_with('a') & where(is.logical) seleciona todas as colunas l√≥gicas cujo nome come√ßa com 'a'.
"

#----26.2.2 Chamando uma √∫nica fun√ß√£o----
"
O segundo argumento para across() define como cada coluna ser√° transformada. Em casos simples, como acima, ser√° uma √∫nica fun√ß√£o existente. Esta √© uma caracter√≠stica bastante especial do R: estamos passando uma fun√ß√£o (median, mean, str_flatten, ...) para outra fun√ß√£o (across). Esta √© uma das caracter√≠sticas que fazem do R uma linguagem de programa√ß√£o funcional.

√â importante notar que estamos passando essa fun√ß√£o para across(), para que across() possa cham√°-la; n√≥s mesmos n√£o estamos chamando. Isso significa que o nome da fun√ß√£o nunca deve ser seguido por (). Se voc√™ esquecer, receber√° um erro:
"
df |> 
  group_by(grp) |> 
  summarize(across(everything(), median()))

"
Este erro surge porque voc√™ est√° chamando a fun√ß√£o sem entrada, por exemplo:
"
median()


#----26.2.3 Chamando m√∫ltiplas fun√ß√µes----
"
Em casos mais complexos, voc√™ pode querer fornecer argumentos adicionais ou realizar m√∫ltiplas transforma√ß√µes. Vamos motivar esse problema com um exemplo simples: o que acontece se tivermos alguns valores ausentes em nossos dados? median() propaga esses valores ausentes, nos dando uma sa√≠da sub√≥tima:
"
rnorm_na <- function(n, n_na, mean = 0, sd = 1) {
  sample(c(rnorm(n - n_na, mean = mean, sd = sd), rep(NA, n_na)))
}

df_miss <- tibble(
  a = rnorm_na(5, 1),
  b = rnorm_na(5, 1),
  c = rnorm_na(5, 2),
  d = rnorm(5)
)
df_miss |> 
  summarize(
    across(a:d, median),
    n = n()
  )

"
Seria bom se pud√©ssemos passar na.rm = TRUE para median() para remover esses valores ausentes. Para fazer isso, em vez de chamar median() diretamente, precisamos criar uma nova fun√ß√£o que chame median() com os argumentos desejados:
"
df_miss |> 
  summarize(
    across(a:d, function(x) median(x, na.rm = TRUE)),
    n = n()
  )

"
Isso √© um pouco prolixo, ent√£o o R vem com um atalho √∫til: para este tipo de fun√ß√£o descart√°vel ou an√¥nima, voc√™ pode substituir function por \2:
"
df_miss |> 
  summarize(
    across(a:d, \(x) median(x, na.rm = TRUE)),
    n = n()
  )

"
Em qualquer caso, across() se expande efetivamente para o seguinte c√≥digo:
"
df_miss |> 
  summarize(
    a = median(a, na.rm = TRUE),
    b = median(b, na.rm = TRUE),
    c = median(c, na.rm = TRUE),
    d = median(d, na.rm = TRUE),
    n = n()
  )

"
Quando removemos os valores ausentes da mediana, seria bom saber quantos valores foram removidos. Podemos descobrir isso fornecendo duas fun√ß√µes para across(): uma para calcular a mediana e a outra para contar os valores ausentes. Voc√™ fornece m√∫ltiplas fun√ß√µes usando uma lista nomeada para .fns:
"
df_miss |> 
  summarize(
    across(a:d, list(
      median = \(x) median(x, na.rm = TRUE),
      n_miss = \(x) sum(is.na(x))
    )),
    n = n()
  )

"
Se voc√™ olhar com aten√ß√£o, pode intuir que as colunas s√£o nomeadas usando uma especifica√ß√£o de cola como {.col}_{.fn} onde .col √© o nome da coluna original e .fn √© o nome da fun√ß√£o. Isso n√£o √© coincid√™ncia! Como voc√™ aprender√° na pr√≥xima se√ß√£o, voc√™ pode usar o argumento .names para fornecer sua pr√≥pria especifica√ß√£o de cola.
"

#----26.2.4 Nomes de colunas----
"
O resultado de across() √© nomeado de acordo com a especifica√ß√£o fornecida no argumento .names. Poder√≠amos especificar o nosso pr√≥prio se quis√©ssemos que o nome da fun√ß√£o viesse primeiro:
"
df_miss |> 
  summarize(
    across(
      a:d,
      list(
        median = \(x) median(x, na.rm = TRUE),
        n_miss = \(x) sum(is.na(x))
      ),
      .names = "{.fn}_{.col}"
    ),
    n = n(),
  )


"
O argumento .names √© particularmente importante quando voc√™ usa across() com mutate(). Por padr√£o, a sa√≠da de across() √© dada os mesmos nomes que as entradas. Isso significa que across() dentro de mutate() substituir√° colunas existentes. Por exemplo, aqui usamos coalesce() para substituir NAs por 0:
"
df_miss |> 
  mutate(
    across(a:d, \(x) coalesce(x, 0))
  )

"
Se voc√™ quiser, em vez disso, criar novas colunas, voc√™ pode usar o argumento .names para dar novos nomes √† sa√≠da:
"
df_miss |> 
  mutate(
    across(a:d, \(x) coalesce(x, 0), .names = "{.col}_na_zero")
  )

#----26.2.5 Filtragem----
"
across() √© uma √≥tima combina√ß√£o para summarize() e mutate(), mas √© mais complicado de usar com filter(), porque voc√™ geralmente combina m√∫ltiplas condi√ß√µes com | ou &. √â claro que across() pode ajudar a criar m√∫ltiplas colunas l√≥gicas, mas e depois? Ent√£o, o dplyr fornece duas variantes de across() chamadas if_any() e if_all():
"
# same as df_miss |> filter(is.na(a) | is.na(b) | is.na(c) | is.na(d))
df_miss |> filter(if_any(a:d, is.na))

# same as df_miss |> filter(is.na(a) & is.na(b) & is.na(c) & is.na(d))
df_miss |> filter(if_all(a:d, is.na))

#----26.2.6 across() em fun√ß√µes----
"
across() √© particularmente √∫til para programar porque permite operar em m√∫ltiplas colunas. Por exemplo, Jacob Scott usa este pequeno auxiliar que envolve v√°rias fun√ß√µes do lubridate para expandir todas as colunas de data em colunas de ano, m√™s e dia:
"
expand_dates <- function(df) {
  df |> 
    mutate(
      across(where(is.Date), list(year = year, month = month, day = mday))
    )
}

df_date <- tibble(
  name = c("Amy", "Bob"),
  date = ymd(c("2009-08-03", "2010-01-16"))
)

df_date |> 
  expand_dates()

"
across() tamb√©m facilita o fornecimento de m√∫ltiplas colunas em um √∫nico argumento, porque o primeiro argumento usa sele√ß√£o arrumada (tidy-select); voc√™ s√≥ precisa lembrar de abra√ßar esse argumento, como discutimos anteriormente. Por exemplo, esta fun√ß√£o calcular√° as m√©dias das colunas num√©ricas por padr√£o. Mas, fornecendo o segundo argumento, voc√™ pode escolher resumir apenas colunas selecionadas:
"
summarize_means <- function(df, summary_vars = where(is.numeric)) {
  df |> 
    summarize(
      across({{ summary_vars }}, \(x) mean(x, na.rm = TRUE)),
      n = n(),
      .groups = "drop"
    )
}
diamonds |> 
  group_by(cut) |> 
  summarize_means()

diamonds |> 
  group_by(cut) |> 
  summarize_means(c(carat, x:z))


#----26.2.7 Vs pivot_longer()----
"
Antes de continuarmos, vale a pena apontar uma conex√£o interessante entre across() e pivot_longer() (Se√ß√£o 5.3). Em muitos casos, voc√™ realiza os mesmos c√°lculos primeiro pivotando os dados e, em seguida, realizando as opera√ß√µes por grupo em vez de por coluna. Por exemplo, pegue este resumo multi-fun√ß√£o:
"
df |> 
  summarize(across(a:d, list(median = median, mean = mean)))

"
Poder√≠amos calcular os mesmos valores pivotando mais longo e depois resumindo:
"
long <- df |> 
  pivot_longer(a:d) |> 
  group_by(name) |> 
  summarize(
    median = median(value),
    mean = mean(value)
  )
long

"
E se voc√™ quisesse a mesma estrutura que across(), voc√™ poderia pivotar novamente:
"
long |> 
  pivot_wider(
    names_from = name,
    values_from = c(median, mean),
    names_vary = "slowest",
    names_glue = "{name}_{.value}"
  )

"
Esta √© uma t√©cnica √∫til para conhecer, porque √†s vezes voc√™ encontrar√° um problema que atualmente n√£o √© poss√≠vel resolver com across(): quando voc√™ tem grupos de colunas com os quais deseja calcular simultaneamente. Por exemplo, imagine que nosso data frame cont√©m tanto valores quanto pesos e queremos calcular uma m√©dia ponderada:
"
df_paired <- tibble(
  a_val = rnorm(10),
  a_wts = runif(10),
  b_val = rnorm(10),
  b_wts = runif(10),
  c_val = rnorm(10),
  c_wts = runif(10),
  d_val = rnorm(10),
  d_wts = runif(10)
)

"
Atualmente, n√£o h√° como fazer isso com across(), mas √© relativamente simples com pivot_longer():
"
df_long <- df_paired |> 
  pivot_longer(
    everything(), 
    names_to = c("group", ".value"), 
    names_sep = "_"
  )
df_long

df_long |> 
  group_by(group) |> 
  summarize(mean = weighted.mean(val, wts))

"
Se necess√°rio, voc√™ poderia pivotar mais largo (pivot_wider()) isso de volta para a forma original.
"

#----26.3 Lendo m√∫ltiplos arquivos----
"
Anteriormente, voc√™ aprendeu a usar dplyr::across() para repetir uma transforma√ß√£o em v√°rias colunas. Nesta se√ß√£o, voc√™ aprender√° a usar purrr::map() para fazer algo com cada arquivo em um diret√≥rio. Vamos come√ßar com um pouco de motiva√ß√£o: imagine que voc√™ tem um diret√≥rio cheio de planilhas do Excel5 que deseja ler. Voc√™ poderia fazer isso com copiar e colar:
"
data2019 <- readxl::read_excel("y2019.xlsx")
data2020 <- readxl::read_excel("y2020.xlsx")
data2021 <- readxl::read_excel("y2021.xlsx")
data2022 <- readxl::read_excel("y2022.xlsx")

"
E depois usar dplyr::bind_rows() para combin√°-las todas juntas:
"
data <- bind_rows(data2019, data2020, data2021, data2022)

"
Voc√™ pode imaginar que isso se tornaria tedioso rapidamente, especialmente se voc√™ tivesse centenas de arquivos, n√£o apenas quatro. As pr√≥ximas se√ß√µes mostram como automatizar esse tipo de tarefa. H√° tr√™s etapas b√°sicas: usar list.files() para listar todos os arquivos em um diret√≥rio, depois usar purrr::map() para ler cada um deles em uma lista, e ent√£o usar purrr::list_rbind() para combin√°-los em um √∫nico data frame. Em seguida, discutiremos como voc√™ pode lidar com situa√ß√µes de heterogeneidade crescente, onde voc√™ n√£o pode fazer exatamente a mesma coisa com cada arquivo.
"

#----26.3.1 Listando arquivos em um diret√≥rio----
"
Como o nome sugere, list.files() lista os arquivos em um diret√≥rio. Voc√™ quase sempre usar√° tr√™s argumentos:
"
#1¬∫ O primeiro argumento, path, √© o diret√≥rio a ser pesquisado. (Como eu fixei o meu diret√≥rio, eu n√£o preciso especificar)
#2¬∫ pattern √© uma express√£o regular usada para filtrar os nomes dos arquivos. O padr√£o mais comum √© algo como [.]xlsx$ ou [.]csv$ para encontrar todos os arquivos com uma extens√£o especificada.
#3¬∫ full.names determina se o nome do diret√≥rio deve ser inclu√≠do na sa√≠da. Quase sempre voc√™ vai querer que isso seja TRUE.

"
Para tornar nosso exemplo motivador concreto, este livro cont√©m uma pasta com 12 planilhas do Excel contendo dados do pacote gapminder. Cada arquivo cont√©m um ano de dados para 142 pa√≠ses. Podemos list√°-los todos com a chamada apropriada para list.files():
"
paths <- list.files("gapminder", pattern = "[.]xlsx$", full.names = TRUE)
paths

#----26.3.2 Listas----
"
Agora que temos esses 12 caminhos, poder√≠amos chamar read_excel() 12 vezes para obter 12 data frames:
"
gapminder_1952 <- readxl::read_excel("data/gapminder/1952.xlsx")
gapminder_1957 <- readxl::read_excel("data/gapminder/1957.xlsx")
gapminder_1962 <- readxl::read_excel("data/gapminder/1962.xlsx")
#...,
gapminder_2007 <- readxl::read_excel("data/gapminder/2007.xlsx")

"
Mas colocar cada planilha em sua pr√≥pria vari√°vel vai dificultar o trabalho com elas alguns passos adiante. Em vez disso, ser√° mais f√°cil trabalhar com elas se as colocarmos em um √∫nico objeto. Uma lista √© a ferramenta perfeita para este trabalho:
"
files <- list(
  readxl::read_excel("data/gapminder/1952.xlsx"),
  readxl::read_excel("data/gapminder/1957.xlsx"),
  readxl::read_excel("data/gapminder/1962.xlsx"),
  #...,
  readxl::read_excel("data/gapminder/2007.xlsx")
)

"
Agora que voc√™ tem esses data frames em uma lista, como voc√™ tira um deles? Voc√™ pode usar files[[i]] para extrair o i-√©simo elemento:
"
files[[i]] #files[[3]]

"
Voltaremos a [[ com mais detalhes futuramente.
"

#----26.3.3 purrr::map() e list_rbind()----
"
O c√≥digo para coletar esses data frames em uma lista 'manualmente' √© basicamente t√£o tedioso de digitar quanto o c√≥digo que l√™ os arquivos um por um. Felizmente, podemos usar purrr::map() para fazer um uso ainda melhor do nosso vetor de caminhos. map() √© semelhante a across(), mas em vez de fazer algo para cada coluna em um data frame, faz algo para cada elemento de um vetor. map(x, f) √© uma abrevia√ß√£o para:
"
list(
  f(x[[1]]),
  f(x[[2]]),
  #...,
  f(x[[n]])
)

"
Portanto, podemos usar map() para obter uma lista de 12 data frames:
"
files <- map(paths, readxl::read_excel)
length(files)

files[[1]]

"
Esta √© outra estrutura de dados que n√£o se exibe particularmente de forma compacta com str(), ent√£o voc√™ pode querer carreg√°-la no RStudio e inspecion√°-la com View().

Agora podemos usar purrr::list_rbind() para combinar essa lista de data frames em um √∫nico data frame:
"
list_rbind(files)

"
Ou poder√≠amos fazer as duas etapas de uma vez em um pipeline:
"
paths |> 
  map(readxl::read_excel) |> 
  list_rbind()

"
E se quisermos passar argumentos extras para read_excel()? Usamos a mesma t√©cnica que usamos com across(). Por exemplo, √© frequentemente √∫til dar uma espiada nas primeiras linhas dos dados com n_max = 1:
"
paths |> 
  map(\(path) readxl::read_excel(path, n_max = 1)) |> 
  list_rbind()

"
Isso deixa claro que algo est√° faltando: n√£o h√° coluna de ano porque esse valor √© registrado no caminho, n√£o nos arquivos individuais. Vamos abordar esse problema a seguir.
"

#----26.3.4 Dados no caminho----
"
√Äs vezes, o nome do arquivo √© um dado em si. Neste exemplo, o nome do arquivo cont√©m o ano, que n√£o √© registrado nos arquivos individuais. Para obter essa coluna no data frame final, precisamos fazer duas coisas:

Primeiro, nomeamos o vetor de caminhos. A maneira mais f√°cil de fazer isso √© com a fun√ß√£o set_names(), que pode receber uma fun√ß√£o. Aqui usamos basename() para extrair apenas o nome do arquivo do caminho completo:
"
paths |> set_names(basename) 

"
Esses nomes s√£o automaticamente levados adiante por todas as fun√ß√µes map(), ent√£o a lista de data frames ter√° esses mesmos nomes:
"
files <- paths |> 
  set_names(basename) |> 
  map(readxl::read_excel)

"
Isso torna esta chamada para map() uma abrevia√ß√£o para:
"
files <- list(
  "1952.xlsx" = readxl::read_excel("data/gapminder/1952.xlsx"),
  "1957.xlsx" = readxl::read_excel("data/gapminder/1957.xlsx"),
  "1962.xlsx" = readxl::read_excel("data/gapminder/1962.xlsx"),
  #...,
  "2007.xlsx" = readxl::read_excel("data/gapminder/2007.xlsx")
)

"
Voc√™ tamb√©m pode usar [[ para extrair elementos pelo nome:
"
files[["1962.xlsx"]]

"
Depois, usamos o argumento names_to em list_rbind() para dizer que salve os nomes em uma nova coluna chamada ano, e ent√£o usamos readr::parse_number() para extrair o n√∫mero da string.
"
paths |> 
  set_names(basename) |> 
  map(readxl::read_excel) |> 
  list_rbind(names_to = "year") |> 
  mutate(year = parse_number(year))

"
Em casos mais complicados, pode haver outras vari√°veis armazenadas no nome do diret√≥rio, ou talvez o nome do arquivo contenha v√°rios peda√ßos de dados. Nesse caso, use set_names() (sem argumentos) para registrar o caminho completo e, em seguida, use tidyr::separate_wider_delim() e similares para transform√°-los em colunas √∫teis.
"
paths |> 
  set_names() |> 
  map(readxl::read_excel) |> 
  list_rbind(names_to = "year") |> 
  separate_wider_delim(year, delim = "/", names = c(NA, "dir", "file")) |> 
  separate_wider_delim(file, delim = ".", names = c("file", "ext"))

#----26.3.5 Salve seu trabalho----
"
Agora que voc√™ fez todo esse trabalho duro para chegar a um data frame organizado e agrad√°vel, √© um √≥timo momento para salvar seu trabalho:
"
gapminder <- paths |> 
  set_names(basename) |> 
  map(readxl::read_excel) |> 
  list_rbind(names_to = "year") |> 
  mutate(year = parse_number(year))

write_csv(gapminder, "gapminder.csv")

"
Agora, quando voc√™ voltar a este problema no futuro, poder√° ler um √∫nico arquivo csv. Para conjuntos de dados grandes e mais ricos, usar parquet pode ser uma escolha melhor do que .csv, como discutido anteriormente.

Se voc√™ est√° trabalhando em um projeto, sugerimos nomear o arquivo que faz esse tipo de trabalho de prepara√ß√£o de dados como 0-cleanup.R. O 0 no nome do arquivo sugere que isso deve ser executado antes de qualquer outra coisa.

Se seus arquivos de dados de entrada mudarem ao longo do tempo, voc√™ pode considerar aprender uma ferramenta como targets para configurar seu c√≥digo de limpeza de dados para ser executado automaticamente sempre que um dos arquivos de entrada for modificado.
"

#----26.3.6 Muitas itera√ß√µes simples----
"
Aqui n√≥s apenas carregamos os dados diretamente do disco e tivemos a sorte de obter um conjunto de dados organizado. Na maioria dos casos, voc√™ precisar√° fazer alguma organiza√ß√£o adicional, e voc√™ tem duas op√ß√µes b√°sicas: voc√™ pode fazer uma rodada de itera√ß√£o com uma fun√ß√£o complexa, ou fazer v√°rias rodadas de itera√ß√£o com fun√ß√µes simples. Na nossa experi√™ncia, a maioria das pessoas opta primeiro por uma itera√ß√£o complexa, mas muitas vezes √© melhor fazer v√°rias itera√ß√µes simples.

Por exemplo, imagine que voc√™ quer ler um monte de arquivos, filtrar valores ausentes, pivotar e depois combinar. Uma maneira de abordar o problema √© escrever uma fun√ß√£o que pega um arquivo e realiza todas essas etapas e ent√£o chamar map() uma vez:
"
process_file <- function(path) {
  df <- read_csv(path)
  
  df |> 
    filter(!is.na(id)) |> 
    mutate(id = tolower(id)) |> 
    pivot_longer(jan:dec, names_to = "month")
}

paths |> 
  map(process_file) |> 
  list_rbind()

"
Alternativamente, voc√™ poderia aplicar cada etapa de process_file() a cada arquivo:
"
paths |> 
  map(read_csv) |> 
  map(\(df) df |> filter(!is.na(id))) |> 
  map(\(df) df |> mutate(id = tolower(id))) |> 
  map(\(df) df |> pivot_longer(jan:dec, names_to = "month")) |> 
  list_rbind()

"
Recomendamos esta abordagem porque impede que voc√™ fique fixado em acertar o primeiro arquivo antes de passar para o resto. Ao considerar todos os dados ao fazer a organiza√ß√£o e limpeza, voc√™ tem mais chances de pensar de forma hol√≠stica e acabar com um resultado de maior qualidade.

Neste exemplo particular, h√° outra otimiza√ß√£o que voc√™ poderia fazer, unindo todos os data frames mais cedo. Assim, voc√™ pode confiar no comportamento regular do dplyr:
"
paths |> 
  map(read_csv) |> 
  list_rbind() |> 
  filter(!is.na(id)) |> 
  mutate(id = tolower(id)) |> 
  pivot_longer(jan:dec, names_to = "month")

#----26.3.7 Dados heterog√™neos----
"
Infelizmente, √†s vezes n√£o √© poss√≠vel ir direto de map() para list_rbind() porque os data frames s√£o t√£o heterog√™neos que list_rbind() falha ou produz um data frame que n√£o √© muito √∫til. Nesse caso, ainda √© √∫til come√ßar carregando todos os arquivos:
"
files <- paths |> 
  map(readxl::read_excel) 

"
Ent√£o, uma estrat√©gia muito √∫til √© capturar a estrutura dos data frames para que voc√™ possa explor√°-la usando suas habilidades de ci√™ncia de dados. Uma maneira de fazer isso √© com esta pr√°tica fun√ß√£o df_types que retorna um tibble com uma linha para cada coluna:
"
df_types <- function(df) {
  tibble(
    col_name = names(df), 
    col_type = map_chr(df, vctrs::vec_ptype_full),
    n_miss = map_int(df, \(x) sum(is.na(x)))
  )
}

df_types(gapminder)

"
Voc√™ pode ent√£o aplicar esta fun√ß√£o a todos os arquivos, e talvez fazer algum pivotamento para facilitar a visualiza√ß√£o das diferen√ßas. Por exemplo, isso torna f√°cil verificar que as planilhas gapminder com as quais estamos trabalhando s√£o todas bastante homog√™neas:
"
files |> 
  map(df_types) |> 
  list_rbind(names_to = "file_name") |> 
  select(-n_miss) |> 
  pivot_wider(names_from = col_name, values_from = col_type)

"
Se os arquivos tiverem formatos heterog√™neos, voc√™ pode precisar fazer mais processamento antes de conseguir mescl√°-los com sucesso. Infelizmente, agora vamos deixar voc√™ descobrir isso por conta pr√≥pria, mas voc√™ pode querer ler sobre map_if() e map_at(). map_if() permite modificar seletivamente elementos de uma lista com base em seus valores; map_at() permite modificar seletivamente elementos com base em seus nomes.
"

#----26.3.8 Lidando com falhas----
"
√Äs vezes, a estrutura dos seus dados pode ser t√£o complexa que voc√™ n√£o consegue ler todos os arquivos com um √∫nico comando. E ent√£o voc√™ encontrar√° uma das desvantagens do map(): ele tem sucesso ou falha como um todo. map() ou ler√° com sucesso todos os arquivos em um diret√≥rio ou falhar√° com um erro, lendo zero arquivos. Isso √© irritante: por que uma falha impede voc√™ de acessar todos os outros sucessos?

Felizmente, o purrr vem com um auxiliar para enfrentar este problema: possibly(). possibly() √© o que √© conhecido como um operador de fun√ß√£o: ele pega uma fun√ß√£o e retorna uma fun√ß√£o com comportamento modificado. Em particular, possibly() muda uma fun√ß√£o de dar erro para retornar um valor que voc√™ especifica:
"
files <- paths |> 
  map(possibly(\(path) readxl::read_excel(path), NULL))

data <- files |> list_rbind()

"
Isso funciona particularmente bem aqui porque list_rbind(), como muitas fun√ß√µes do tidyverse, automaticamente ignora NULLs.

Agora voc√™ tem todos os dados que podem ser lidos facilmente, e √© hora de enfrentar a parte dif√≠cil de descobrir por que alguns arquivos falharam ao carregar e o que fazer a respeito. Comece obtendo os caminhos que falharam:
"
failed <- map_vec(files, is.null)
paths[failed]

"
Em seguida, chame a fun√ß√£o de importa√ß√£o novamente para cada falha e descubra o que deu errado.
"

#----26.4 Salvando m√∫ltiplas sa√≠das----
"
Voc√™ aprendeu sobre map(), que √© √∫til para ler v√°rios arquivos em um √∫nico objeto. Nesta se√ß√£o, agora exploraremos o tipo oposto de problema: como voc√™ pode pegar um ou mais objetos R e salv√°-los em um ou mais arquivos? Vamos explorar esse desafio usando tr√™s exemplos:
"
#1¬∫ Salvando m√∫ltiplos data frames em um √∫nico banco de dados.
#2¬∫ Salvando m√∫ltiplos data frames em v√°rios arquivos .csv.
#3¬∫ Salvando m√∫ltiplos gr√°ficos em v√°rios arquivos .png.

#----26.4.1 Escrevendo em um banco de dados----
"
√Äs vezes, ao trabalhar com muitos arquivos de uma vez, n√£o √© poss√≠vel ajustar todos os seus dados na mem√≥ria de uma s√≥ vez, e voc√™ n√£o pode usar map(files, read_csv). Uma abordagem para lidar com esse problema √© carregar seus dados em um banco de dados para que voc√™ possa acessar apenas as partes de que precisa com dbplyr.

Se voc√™ tiver sorte, o pacote de banco de dados que voc√™ est√° usando fornecer√° uma fun√ß√£o pr√°tica que recebe um vetor de caminhos e carrega todos no banco de dados. Este √© o caso com duckdb_read_csv() do duckdb:
"
con <- DBI::dbConnect(duckdb::duckdb())
duckdb::duckdb_read_csv(con, "gapminder", paths)

"
Isso funcionaria bem aqui, mas n√£o temos arquivos csv, e sim planilhas do Excel. Ent√£o, vamos ter que fazer isso 'manualmente'. Aprender a fazer isso manualmente tamb√©m ajudar√° quando voc√™ tiver um monte de csvs e o banco de dados com o qual est√° trabalhando n√£o tiver uma fun√ß√£o √∫nica que carregue todos eles.

Precisamos come√ßar criando uma tabela que preencheremos com dados. A maneira mais f√°cil de fazer isso √© criando um template, um data frame fict√≠cio que cont√©m todas as colunas que queremos, mas apenas uma amostra dos dados. Para os dados do gapminder, podemos fazer esse template lendo um √∫nico arquivo e adicionando o ano a ele:
"
template <- readxl::read_excel(paths[[1]])
template$year <- 1952
template

"
Agora podemos nos conectar ao banco de dados e usar DBI::dbCreateTable() para transformar nosso template em uma tabela de banco de dados:
"
con <- DBI::dbConnect(duckdb::duckdb())
DBI::dbCreateTable(con, "gapminder", template)

"
dbCreateTable() n√£o usa os dados em template, apenas os nomes e tipos das vari√°veis. Ent√£o, se inspecionarmos a tabela gapminder agora, voc√™ ver√° que ela est√° vazia, mas tem as vari√°veis que precisamos com os tipos que esperamos:
"
con |> tbl("gapminder")

"
Em seguida, precisamos de uma fun√ß√£o que pegue um √∫nico caminho de arquivo, leia-o no R e adicione o resultado √† tabela gapminder. Podemos fazer isso combinando read_excel() com DBI::dbAppendTable():
"
append_file <- function(path) {
  df <- readxl::read_excel(path)
  df$year <- parse_number(basename(path))
  
  DBI::dbAppendTable(con, "gapminder", df)
}

"
Agora precisamos chamar append_file() uma vez para cada elemento de paths. Isso certamente √© poss√≠vel com map():
"
paths |> map(append_file)

"
Mas n√£o nos importamos com a sa√≠da de append_file(), ent√£o, em vez de map(), √© um pouco melhor usar walk(). walk() faz exatamente a mesma coisa que map(), mas descarta a sa√≠da:
"
paths |> walk(append_file)

"
Agora podemos ver se temos todos os dados em nossa tabela:
"
con |> 
  tbl("gapminder") |> 
  count(year)

#----26.4.2 Escrevendo arquivos csv----
"
O mesmo princ√≠pio b√°sico se aplica se quisermos escrever v√°rios arquivos csv, um para cada grupo. Vamos imaginar que queremos pegar os dados de ggplot2::diamonds e salvar um arquivo csv para cada tipo de clareza (clarity). Primeiro, precisamos fazer esses conjuntos de dados individuais. H√° muitas maneiras de fazer isso, mas h√° uma maneira que gostamos particularmente: group_nest().
"
by_clarity <- diamonds |> 
  group_nest(clarity)

by_clarity

"
Isso nos d√° um novo tibble com oito linhas e duas colunas. clarity √© a nossa vari√°vel de agrupamento e data √© uma coluna-lista contendo um tibble para cada valor √∫nico de clarity:
"
by_clarity$data[[1]]

"
Enquanto estamos aqui, vamos criar uma coluna que d√™ o nome do arquivo de sa√≠da, usando mutate() e str_glue():
"
by_clarity <- by_clarity |> 
  mutate(path = str_glue("diamonds-{clarity}.csv"))

by_clarity

"
Ent√£o, se f√¥ssemos salvar esses data frames manualmente, poder√≠amos escrever algo como:
"
write_csv(by_clarity$data[[1]], by_clarity$path[[1]])
write_csv(by_clarity$data[[2]], by_clarity$path[[2]])
write_csv(by_clarity$data[[3]], by_clarity$path[[3]])
#...
write_csv(by_clarity$by_clarity[[8]], by_clarity$path[[8]])

"
Isso √© um pouco diferente dos nossos usos anteriores de map() porque h√° dois argumentos que est√£o mudando, n√£o apenas um. Isso significa que precisamos de uma nova fun√ß√£o: map2(), que varia tanto o primeiro quanto o segundo argumento. E como novamente n√£o nos importamos com a sa√≠da, queremos walk2() em vez de map2(). Isso nos d√°:
"
walk2(by_clarity$data, by_clarity$path, write_csv)

#----26.4.3 Salvando gr√°ficos----
"
Podemos adotar a mesma abordagem b√°sica para criar muitos gr√°ficos. Primeiro, vamos fazer uma fun√ß√£o que desenhe o gr√°fico que queremos:
"
carat_histogram <- function(df) {
  ggplot(df, aes(x = carat)) + geom_histogram(binwidth = 0.1)  
}

carat_histogram(by_clarity$data[[1]])

"
Agora podemos usar map() para criar uma lista de muitos gr√°ficos7 e seus caminhos de arquivo finais:
"
by_clarity <- by_clarity |> 
  mutate(
    plot = map(data, carat_histogram),
    path = str_glue("clarity-{clarity}.png")
  )

"
Ent√£o use walk2() com ggsave() para salvar cada gr√°fico:
"
walk2(
  by_clarity$path,
  by_clarity$plot,
  \(path, plot) ggsave(path, plot, width = 6, height = 6)
)

"
Isso √© uma abrevia√ß√£o para:
"
ggsave(by_clarity$path[[1]], by_clarity$plot[[1]], width = 6, height = 6)
ggsave(by_clarity$path[[2]], by_clarity$plot[[2]], width = 6, height = 6)
ggsave(by_clarity$path[[3]], by_clarity$plot[[3]], width = 6, height = 6)
#...
ggsave(by_clarity$path[[8]], by_clarity$plot[[8]], width = 6, height = 6)

#----Cap√≠tulo 27 : Um Guia de Campo para o R Base----

#----27.1 Introdu√ß√£o----
"
Para finalizar a se√ß√£o de programa√ß√£o, vamos dar um r√°pido tour pelas fun√ß√µes mais importantes do R base que n√£o discutimos em outro lugar no livro. Essas ferramentas s√£o particularmente √∫teis √† medida que voc√™ faz mais programa√ß√£o e ajudar√£o voc√™ a ler o c√≥digo que encontrar√° na pr√°tica.

Este √© um bom lugar para lembrar que o tidyverse n√£o √© a √∫nica maneira de resolver problemas de ci√™ncia de dados. N√≥s ensinamos o tidyverse neste
livro porque os pacotes do tidyverse compartilham uma filosofia de design comum, aumentando a consist√™ncia entre as fun√ß√µes e tornando cada nova fun√ß√£o ou pacote um pouco mais f√°cil de aprender e usar. N√£o √© poss√≠vel usar o tidyverse sem usar o R base, ent√£o na verdade j√° ensinamos muitas fun√ß√µes do R base: desde library() para carregar pacotes, at√© sum() e mean() para resumos num√©ricos, at√© os tipos de dados factor, date e POSIXct, e claro, todos os operadores b√°sicos como +, -, /, *, |, &, e !. O que n√£o focamos at√© agora s√£o os fluxos de trabalho do R base, ent√£o vamos destacar alguns deles neste cap√≠tulo.

Depois de ler este livro, voc√™ aprender√° outras abordagens para os mesmos problemas usando R base, data.table e outros pacotes. Voc√™ certamente encontrar√° essas outras abordagens quando come√ßar a ler o c√≥digo R escrito por outros, especialmente se estiver usando o StackOverflow. √â 100% aceit√°vel escrever c√≥digo que usa uma mistura de abordagens, e n√£o deixe ningu√©m lhe dizer o contr√°rio!

Agora vamos nos concentrar em quatro grandes t√≥picos: subconjunto com [, subconjunto com [[ e $, a fam√≠lia de fun√ß√µes apply e loops for. Para finalizar, discutiremos brevemente duas fun√ß√µes essenciais de plotagem.
"

#----27.1.1 Pr√©-requisitos----
"
Este pacote se concentra no R base, portanto n√£o tem pr√©-requisitos reais, mas carregaremos o tidyverse para explicar algumas das diferen√ßas.
"
library(tidyverse)

#----27.2 Selecionando m√∫ltiplos elementos com [----
"
[ √© usado para extrair subcomponentes de vetores e data frames, e √© chamado como x[i] ou x[i, j]. Nesta se√ß√£o, apresentaremos a voc√™ o poder do [, mostrando primeiro como voc√™ pode us√°-lo com vetores e, em seguida, como os mesmos princ√≠pios se estendem de maneira direta para estruturas bidimensionais (2d) como data frames. Ent√£o, ajudaremos voc√™ a consolidar esse conhecimento, mostrando como v√°rios verbos do dplyr s√£o casos especiais de [.
"

#----27.2.1 Subconjuntos de vetores----
"
Existem cinco tipos principais de elementos que voc√™ pode usar para fazer subconjuntos de um vetor, ou seja, o que pode ser o i em x[i]:
"
#1¬∫ Existem cinco tipos principais de elementos que voc√™ pode usar para fazer subconjuntos de um vetor, ou seja, o que pode ser o i em x[i]:
x <- c("one", "two", "three", "four", "five")
x[c(3, 2, 5)]
# Ao repetir uma posi√ß√£o, voc√™ pode realmente fazer uma sa√≠da mais longa do que a entrada, tornando o termo "subconjunto" um pouco inadequado.
x[c(1, 1, 5, 5, 5, 2)]
#2¬∫ Um vetor de inteiros negativos. Valores negativos descartam os elementos nas posi√ß√µes especificadas:
x[c(-1, -3, -5)]
#3¬∫ Um vetor l√≥gico. Fazer subconjuntos com um vetor l√≥gico mant√©m todos os valores correspondentes a um valor TRUE. Isso √© mais √∫til em conjunto com as fun√ß√µes de compara√ß√£o.
x <- c(10, 3, NA, 5, 8, 1, NA)

# All non-missing values of x
x[!is.na(x)]

# All even (or missing!) values of x
x[x %% 2 == 0]

# Ao contr√°rio do filter(), √≠ndices NA ser√£o inclu√≠dos na sa√≠da como NAs.
#4¬∫ Um vetor de caracteres. Se voc√™ tem um vetor nomeado, pode fazer subconjuntos dele com um vetor de caracteres:
x <- c(abc = 1, def = 2, xyz = 5)
x[c("xyz", "def")]
# Assim como ao fazer subconjuntos com inteiros positivos, voc√™ pode usar um vetor de caracteres para duplicar entradas individuais.
#5¬∫ Nada. O tipo final de subconjunto √© nada, x[], que retorna o x completo. Isso n√£o √© √∫til para subconjuntos de vetores, mas, como veremos em breve, √© √∫til ao fazer subconjuntos de estruturas 2d como tibbles.

#----27.2.2 Subconjuntos de data frames----
"
Existem v√°rias maneiras1 diferentes de usar [ com um data frame, mas a mais importante √© selecionar linhas e colunas independentemente com df[rows, cols]. Aqui, rows e cols s√£o vetores como descrito acima. Por exemplo, df[rows, ] e df[, cols] selecionam apenas linhas ou apenas colunas, usando o subconjunto vazio para preservar a outra dimens√£o.

Aqui est√£o alguns exemplos:
"
df <- tibble(
  x = 1:3, 
  y = c("a", "e", "f"), 
  z = runif(3)
)

# Select first row and second column
df[1, 2]

# Select all rows and columns x and y
df[, c("x" , "y")]

# Select rows where `x` is greater than 1 and all columns
df[df$x > 1, ]

"
Voltaremos ao $ em breve, mas voc√™ deve ser capaz de adivinhar o que df$x faz a partir do contexto: ele extrai a vari√°vel x de df. Precisamos us√°-lo aqui porque [ n√£o usa avalia√ß√£o arrumada (tidy evaluation), ent√£o voc√™ precisa ser expl√≠cito sobre a fonte da vari√°vel x.

H√° uma diferen√ßa importante entre tibbles e data frames quando se trata de [. Neste livro, usamos principalmente tibbles, que s√£o data frames, mas eles ajustam alguns comportamentos para tornar sua vida um pouco mais f√°cil. Na maioria dos lugares, voc√™ pode usar 'tibble' e 'data frame' de forma intercambi√°vel, ent√£o quando queremos chamar aten√ß√£o especial para o data frame integrado do R, escreveremos data.frame. Se df √© um data.frame, ent√£o df[, cols] retornar√° um vetor se cols selecionar uma √∫nica coluna e um data frame se selecionar mais de uma coluna. Se df √© um tibble, ent√£o [ sempre retornar√° um tibble.
"
df1 <- data.frame(x = 1:3)
df1[, "x"]

df2 <- tibble(x = 1:3)
df2[, "x"]

"
Uma maneira de evitar essa ambiguidade com data.frames √© especificar explicitamente drop = FALSE:
"
df1[, "x" , drop = FALSE]

#----27.2.3 Equivalentes dplyr----
"
V√°rios verbos do dplyr s√£o casos especiais de [:
"
#1¬∫ filter() √© equivalente a subconjuntar as linhas com um vetor l√≥gico, tomando cuidado para excluir valores ausentes:
df <- tibble(
  x = c(2, 3, 1, 1, NA), 
  y = letters[1:5], 
  z = runif(5)
)
df |> filter(x > 1)

# same as
df[!is.na(df$x) & df$x > 1, ]
# Outra t√©cnica comum na pr√°tica √© usar which() pelo seu efeito colateral de descartar valores ausentes: df[which(df$x > 1), ].
#2¬∫ arrange() √© equivalente a subconjuntar as linhas com um vetor de inteiros, geralmente criado com order():
df |> arrange(x, y)

# same as
df[order(df$x, df$y), ]

# Voc√™ pode usar order(decreasing = TRUE) para ordenar todas as colunas em ordem decrescente ou -rank(col) para ordenar colunas em ordem decrescente individualmente.
#3¬∫ Tanto select() quanto relocate() s√£o semelhantes a subconjuntar as colunas com um vetor de caracteres:
df |> select(x, z)

# same as
df[, c("x", "z")]

"
O R base tamb√©m fornece uma fun√ß√£o que combina as caracter√≠sticas de filter() e select() chamada subset():
"
df |> 
  filter(x > 1) |> 
  select(y, z)

# same as 
df |> subset(x > 1, c(y, z))

"
Essa fun√ß√£o foi a inspira√ß√£o para grande parte da sintaxe do dplyr.
"

#----27.3 Selecionando um √∫nico elemento com $ e [[----
"
[, que seleciona muitos elementos, √© pareado com [[ e $, que extraem um √∫nico elemento. Nesta se√ß√£o, mostraremos como usar [[ e $ para extrair colunas de data frames, discutiremos mais algumas diferen√ßas entre data.frames e tibbles, e enfatizaremos algumas diferen√ßas importantes entre [ e [[ quando usados com listas.
"

#----27.3.1 Data frames----
"
[[ e $ podem ser usados para extrair colunas de um data frame. [[ pode acessar por posi√ß√£o ou por nome, e $ √© especializado para acesso por nome:
"
tb <- tibble(
  x = 1:4,
  y = c(10, 4, 1, 21)
)

# by position
tb[[1]]

# by name
tb[["x"]]
tb$x

"
Eles tamb√©m podem ser usados para criar novas colunas, o equivalente no R base do mutate():
"
tb$z <- tb$x + tb$y
tb

"
Existem v√°rias outras abordagens no R base para criar novas colunas, incluindo transform(), with() e within(). Hadley coletou alguns exemplos em https://gist.github.com/hadley/1986a273e384fb2d4d752c18ed71bedf.

Usar $ diretamente √© conveniente ao realizar resumos r√°pidos. Por exemplo, se voc√™ s√≥ quer encontrar o tamanho do maior diamante ou os poss√≠veis valores de corte, n√£o h√° necessidade de usar summarize():
"
max(diamonds$carat)

levels(diamonds$cut)

"
O dplyr tamb√©m fornece um equivalente a [[/$ que n√£o mencionamos no in√≠cio: pull(). pull() aceita um nome de vari√°vel ou posi√ß√£o de vari√°vel e retorna apenas aquela coluna. Isso significa que poder√≠amos reescrever o c√≥digo acima para usar o pipe:
"
diamonds |> pull(carat) |> max()

diamonds |> pull(cut) |> levels()

#----27.3.2 Tibbles----
"
H√° algumas diferen√ßas importantes entre tibbles e data.frames base no que diz respeito ao $. Data frames correspondem ao prefixo de qualquer nome de vari√°vel (o chamado correspond√™ncia parcial) e n√£o reclamam se uma coluna n√£o existir:
"
df <- data.frame(x1 = 1)
df$x
df$z

"
Tibbles s√£o mais rigorosos: eles s√≥ correspondem exatamente aos nomes das vari√°veis e gerar√£o um aviso se a coluna que voc√™ est√° tentando acessar n√£o existir:
"
tb <- tibble(x1 = 1)

tb$x
tb$z

"
Por essa raz√£o, √†s vezes brincamos que tibbles s√£o pregui√ßosos e mal-humorados: eles fazem menos e reclamam mais.
"

#----27.3.3 Listas----
"
[[ e $ tamb√©m s√£o realmente importantes para trabalhar com listas, e √© importante entender como eles diferem de [. Vamos ilustrar as diferen√ßas com uma lista chamada l:
"
l <- list(
  a = 1:3, 
  b = "a string", 
  c = pi, 
  d = list(-1, -5)
)

#1¬∫ [ extrai uma sublista. N√£o importa quantos elementos voc√™ extraia, o resultado ser√° sempre uma lista.
str(l[1:2])

str(l[1])

str(l[4])
# Assim como com vetores, voc√™ pode fazer subconjuntos com um vetor l√≥gico, inteiro ou de caracteres.
#2¬∫ [[ e $ extraem um √∫nico componente de uma lista. Eles removem um n√≠vel de hierarquia da lista.
str(l[[1]])

str(l[[4]])

str(l$a)

"
A diferen√ßa entre [ e [[ √© particularmente importante para listas porque [[ penetra na lista, enquanto [ retorna uma nova lista, menor.

Esse mesmo princ√≠pio se aplica quando voc√™ usa [ 1d com um data frame: df['x'] retorna um data frame de uma coluna e df[['x']] retorna um vetor.
"

#----27.4 Fam√≠lia Apply----
"
Anteriormente, voc√™ aprendeu t√©cnicas do tidyverse para itera√ß√£o como dplyr::across() e a fam√≠lia de fun√ß√µes map. Nesta se√ß√£o, voc√™ aprender√° sobre seus equivalentes no R base, a fam√≠lia apply. Neste contexto, apply e map s√£o sin√¥nimos porque outra maneira de dizer 'mapear uma fun√ß√£o sobre cada elemento de um vetor' √© 'aplicar uma fun√ß√£o sobre cada elemento de um vetor'. Aqui daremos a voc√™ uma vis√£o geral r√°pida dessa fam√≠lia para que voc√™ possa reconhec√™-los na pr√°tica.

O membro mais importante desta fam√≠lia √© lapply(), que √© muito semelhante a purrr::map(). Na verdade, como n√£o usamos nenhum dos recursos mais avan√ßados de map(), voc√™ pode substituir cada chamada de map() por lapply().

N√£o h√° um equivalente exato no R base para across(), mas voc√™ pode chegar perto usando [ com lapply(). Isso funciona porque, por baixo dos panos, os data frames s√£o listas de colunas, ent√£o chamar lapply() em um data frame aplica a fun√ß√£o a cada coluna.
"
df <- tibble(a = 1, b = 2, c = "a", d = "b", e = 4)

# First find numeric columns
num_cols <- sapply(df, is.numeric)
num_cols

df[, num_cols] <- lapply(df[, num_cols, drop = FALSE], \(x) x * 2)
df

"
O c√≥digo acima usa uma nova fun√ß√£o, sapply(). √â semelhante a lapply(), mas sempre tenta simplificar o resultado, da√≠ o s em seu nome, produzindo aqui um vetor l√≥gico em vez de uma lista. N√£o recomendamos us√°-lo para programa√ß√£o, porque a simplifica√ß√£o pode falhar e dar um tipo inesperado, mas geralmente √© bom para uso interativo. O purrr tem uma fun√ß√£o semelhante chamada map_vec() que n√£o mencionamos antes.

O R base fornece uma vers√£o mais rigorosa do sapply() chamada vapply(), abrevia√ß√£o de vector apply. Ele recebe um argumento adicional que especifica o tipo esperado, garantindo que a simplifica√ß√£o ocorra da mesma forma, independentemente da entrada. Por exemplo, poder√≠amos substituir a chamada de sapply() acima com este vapply() onde especificamos que esperamos que is.numeric() retorne um vetor l√≥gico de comprimento 1:
"
vapply(df, is.numeric, logical(1))

"
A distin√ß√£o entre sapply() e vapply() √© realmente importante quando est√£o dentro de uma fun√ß√£o (porque faz uma grande diferen√ßa na robustez da fun√ß√£o a entradas incomuns), mas geralmente n√£o importa na an√°lise de dados.

Outro membro importante da fam√≠lia apply √© tapply(), que calcula um resumo agrupado √∫nico:
"
diamonds |> 
  group_by(cut) |> 
  summarize(price = mean(price))

tapply(diamonds$price, diamonds$cut, mean)

"
Infelizmente, tapply() retorna seus resultados em um vetor nomeado, o que requer algumas gin√°sticas se voc√™ quiser coletar v√°rios resumos e vari√°veis de agrupamento em um data frame (certamente √© poss√≠vel n√£o fazer isso e apenas trabalhar com vetores soltos, mas em nossa experi√™ncia isso apenas adia o trabalho). Se voc√™ quiser ver como pode usar tapply() ou outras t√©cnicas do R base para realizar outros resumos agrupados, Hadley coletou algumas t√©cnicas em um gist.

O membro final da fam√≠lia apply √© o pr√≥prio apply(), que funciona com matrizes e arrays. Em particular, cuidado com apply(df, 2, something), que √© uma maneira lenta e potencialmente perigosa de fazer lapply(df, something). Isso raramente surge na ci√™ncia de dados porque geralmente trabalhamos com data frames e n√£o matrizes.
"

#----27.5 Loops for----
"
Os loops for s√£o o bloco fundamental de constru√ß√£o da itera√ß√£o que tanto as fam√≠lias apply quanto map usam por baixo dos panos. Os loops for s√£o ferramentas poderosas e gerais que s√£o importantes de aprender √† medida que voc√™ se torna um programador R mais experiente. 

A estrutura b√°sica de um loop for √© assim:

for (element in vector) {
  # do something with element
}

O uso mais direto de loops for √© para alcan√ßar o mesmo efeito que walk(): chamar alguma fun√ß√£o com um efeito colateral em cada elemento de uma lista. Por exemplo, em vez de usar walk():
"
paths |> walk(append_file)

"
Poder√≠amos ter usado um loop for:
"
for (path in paths) {
  append_file(path)
}

"
As coisas ficam um pouco mais complicadas se voc√™ quiser salvar a sa√≠da do loop for, por exemplo, lendo todos os arquivos do Excel em um diret√≥rio como fizemos.
"
paths <- dir("gapminder", pattern = "\\.xlsx$", full.names = TRUE)
files <- map(paths, readxl::read_excel)

"
H√° algumas t√©cnicas diferentes que voc√™ pode usar, mas recomendamos ser expl√≠cito sobre como ser√° a sa√≠da antecipadamente. Neste caso, vamos querer uma lista do mesmo comprimento que paths, que podemos criar com vector():
"
files <- vector("list", length(paths))

"
Ent√£o, em vez de iterar sobre os elementos de paths, vamos iterar sobre seus √≠ndices, usando seq_along() para gerar um √≠ndice para cada elemento de paths:
"
seq_along(paths)

"
Usar os √≠ndices √© importante porque nos permite vincular cada posi√ß√£o na entrada com a posi√ß√£o correspondente na sa√≠da:
"
for (i in seq_along(paths)) {
  files[[i]] <- readxl::read_excel(paths[[i]])
}

"
Para combinar a lista de tibbles em um √∫nico tibble, voc√™ pode usar do.call() + rbind():
"
do.call(rbind, files)

"
Em vez de criar uma lista e salvar os resultados √† medida que avan√ßamos, uma abordagem mais simples √© construir o data frame pe√ßa por pe√ßa:
"
out <- NULL
for (path in paths) {
  out <- rbind(out, readxl::read_excel(path))
}

"
Recomendamos evitar este padr√£o porque ele pode se tornar muito lento quando o vetor √© muito longo. Esta √© a fonte do mito persistente de que os loops for s√£o lentos: eles n√£o s√£o, mas crescer um vetor iterativamente √©.
"

#----27.6 Gr√°ficos----
"
Muitos usu√°rios de R que n√£o usam o tidyverse preferem o ggplot2 para plotagem devido a recursos √∫teis como padr√µes sensatos, legendas autom√°ticas e uma apar√™ncia moderna. No entanto, as fun√ß√µes de plotagem do R base ainda podem ser √∫teis porque s√£o muito concisas ‚Äî √© preciso muito pouco digita√ß√£o para fazer um gr√°fico explorat√≥rio b√°sico.

H√° dois tipos principais de gr√°ficos base que voc√™ ver√° na pr√°tica: gr√°ficos de dispers√£o e histogramas, produzidos com plot() e hist() respectivamente. Aqui est√° um exemplo r√°pido do conjunto de dados diamonds:
"
hist(diamonds$carat)

plot(diamonds$carat, diamonds$price)

"
Observe que as fun√ß√µes de plotagem base funcionam com vetores, ent√£o voc√™ precisa extrair colunas do data frame usando $ ou alguma outra t√©cnica.
"