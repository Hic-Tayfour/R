---
title: "1 - Começando com DoubleML"
author: "Hicham Munir Tayfour"
output:
  html_document:
    theme: flatly       
    toc: true           
    toc_float: true     
    code_folding: hide  
    highlight: tango    
---

## 1.1 - Introdução

O objetivo dos estudos de caso a seguir é demonstrar as funcionalidades principais do [**DoubleML**](https://docs.doubleml.org/stable/index.html#doubleml-package).

## 1.2 - Dados

Para nosso estudp de cao, faremos o download do conjunto de dados *Bonus do experimento de Bônus de Reemprego da Pensilvânia* e, como segundo exemplo, simularemos dados a partir de um modelo de regressão linear parcial.

```{r message = FALSE, warning = FALSE}
library(DoubleML)

# Carregar os dados de Bônus

df_bonus <- fetch_bonus(return_type = "data.table")

# Simulando Dados

set.seed(3141)
n_obs = 500
n_vars = 100
theta = 3

X = matrix(
  rnorm(n_obs * n_vars),
  nrow = n_obs,
  ncol = n_vars 
)

d = X[, 1:3]%*%c(5,5,5) + rnorm(n_obs)

y = theta*d + X[, 1:3]%*%c(5,5,5) + rnorm(n_obs)

df_bonus

```

## 1.3 - O Modelo Causal

Como exemplo, especificamos um modelo de regressão linear pasrcial (**PLR**).**PLR** assumem a seguinte forma :

$$
Y = D\theta_0 + g_0(X) + \zeta \ \ , \ \ E(\zeta|D,X) = 0 
$$

$$
D = m_0(X) + V \ \ , \ \ E(V|X) = 0 
$$

onde $Y$ é a variável de desfecho (ou resultado), e $D$ é a variável de política de interesse. O vetor de alta dimensionalidade $X = (X+1,...,X_p)$ consiste em outras covariáveis de confusão, e $\zeta$ e $V$ são erros estocáticos. Para mais detalhes sobre os modelos implementados no pacote [**DoubleML**](https://docs.doubleml.org/stable/index.html#doubleml-package), consulte o guia do usuário na seção [**Models**](https://docs.doubleml.org/stable/guide/models.html#models).

## 1.5 - O BackEnd de dados: `DoubleMLData`

[**DoubleML**](https://docs.doubleml.org/stable/index.html#doubleml-package) oferece interfaces tanto para dataframes quanto para arrays. Detlhes sobre o backend dos dados e as interaces podem ser encontrados no [**guia de usuário**](https://docs.doubleml.org/stable/guide/data_backend.html#data-backend).A classe `DoubleMLData` funciona como um backend de dados e pode ser inicializada a partir de um *dataframe*, especificando-se:

-   a coluna `y_col = 'inuidur1'`, que representa a variável de desfecho $\rightarrow Y$
-   a(s) coluna(s) `d_cols =  'tg'`, que representa(m) a(s) variável(is) de tratamento $\rightarrow D$
-   e as colunas `x_cols`, que espécificam as variáveis de confundimento (*conounders*)$\rightarrow X$

Alternativamente, também é possível utilizar uma interface baseadas em *arrays*, como mostrado abaixo parta os dados simulados.

```{r message = FALSE, warning = FALSE}

# Especificando os dado e as variáveis do modelo causal

dml_data_bonus = DoubleMLData$new(df_bonus,
                            y_col = "inuidur1",
                            d_cols = "tg",
                            x_cols = c("female", "black", "othrace", "dep1", "dep2",
                                        "q2", "q3", "q4", "q5", "q6", "agelt35", "agegt54",
                                        "durable", "lusd", "husd")
                            )

print(dml_data_bonus)

# Interface da Matriz para DoubleML

dml_data_sim = double_ml_data_from_matrix(X = X, 
                                     y = y,
                                     d = d)

dml_data_sim

```

## 1.6 - Modelos auxiliares (*Learners*) para estimar os modelos de *nuisance*

Para estimar nosso modelode **PLR** com o algoritmo de *double machine laerning*, primeiro precisamos especificar os *learners* para estimar $m_0$ e $g_0$. Para o conjunto de dados bonus, utilizaresmos um modelo de regressão por *random forest*. Já para os dados simulados a partir simulados. A implemnetação do [**DoubleML**](https://docs.doubleml.org/stable/index.html#doubleml-package) é baseada no *meta-packages* [**scikit-learn**](https://scikit-learn.org/)(Pedregosa et al., 2011) para Python e [**mlr3**](https://mlr3.mlr-org.com/)(Lang et al, 2019) para R. Para mais detalhes sobre a especificaçlão dos *learners* e seus hiperparâmetros, consulte o guia de usuário na seção [**Learners, hyperparameters and hyperparameter tuning.**](Learners,%20hyperparameters%20and%20hyperparameter%20tuning.)

```{r message = FALSE, warning = FALSE}
library(mlr3)
library(mlr3learners)

# Ignorar mensages do pacote mlr3 durante ajuste

lgr::get_logger("mlr3")$set_threshold("warn")

learnner = lrn("regr.ranger", 
                num.trees = 500,
                max.depth = 5,
                min.node.size = 2
                )

ml_l_bonus = learnner$clone()

ml_m_bonus = learnner$clone()

learnner = lrn("regr.cv_glmnet", 
               s = "lambda.min")

ml_l_sim = learnner$clone()

ml_m_sim = learnner$clone()

```

## 1.7 - *Cross-fitting*, algoritmos DML e funções de score Neyman-ortogonais

Ao inicializar o objeto para modelos **PLR** com `DoubleMLPLR`, é possível definir os parâmetros adicionais relacionados aos reamostramento:

-   O número de partições (*folds*) usado no *cross-fitting* com `n_folds` (padrão: `n_folds = 5`)

-   O número de repetições no *cross-fitting* repetindo `n_rep` (padrão: `n_rep = 1`)

Além disso, pode-se escolher entre os algoritmos `dml1` e `dlm2` por meio do argumento `dml_procedure` (padrão: `dml2`)

Dependendo do modelo causal, também é possível escolher entre diferentes funções de score (ou de momento) Neyman-ortogonais. Para o modelo **PLR**, a função de score padrão é `partalling out`, ou seja:

$$
\phi(W;\theta,\eta) := [Y - l(x) -\theta(D-m(X))][D-m(X)]
$$

> Not que com esse tipo de score, não estimos diretamente o parâmetro $g_0(X)$, mas sim a expectativa condicional de $Y$ dado $X,l=E[Y|X]$

O guia de usuário fornece detalhes sobre:

-   [Sample-splitting, cross-fitting and repeated cross-fitting](https://docs.doubleml.org/stable/guide/resampling.html#resampling)

-   [Double machine learning](https://docs.doubleml.org/stable/guide/algorithms.html#algorithms)

-   [Score Functions](https://docs.doubleml.org/stable/guide/scores.html#scores)

## 1.8 - Estimando os modelos Double/Debiased Machine Learning Models

Agora inicializamos os objetos `DoubleMLPLR` para os nossos exemplos, utilizando os parâmetros padrão. Os modelos são estimados por meio do método `fit()` e, por exemplo, podemos inspecionar o efeito estimado do tratamento utilizando a propriedade `summary`. Um resumo mais detalhado dos resuldados pode ser obtido por meio da representação em string do objeto. Além do método `fit()`, as classes de modelo [DoubleML](https://docs.doubleml.org/stable/index.html#doubleml-package) também oferecem funciolidades para realizar inferência estatística como `bootstrap()`, `confint()` e `p_adjust()`, para detalhes veja o guia de usuário [Variance estimation and confidence intervals.](https://docs.doubleml.org/stable/guide/se_confint.html#se-confint)

```{r message = FALSE, warning = FALSE}

set.seed(3141)

obj_dml_plr_bonus = DoubleMLPLR$new(dml_data_bonus,
                                    ml_l = ml_l_bonus,
                                    ml_m = ml_m_bonus)

obj_dml_plr_bonus$fit()

print(obj_dml_plr_bonus)

obj_dml_plr_sim = DoubleMLPLR$new(dml_data_sim,
                                    ml_l = ml_l_sim,
                                    ml_m = ml_m_sim)

obj_dml_plr_sim$fit()

print(obj_dml_plr_sim)


```
