---
title: "3 - Modelos"
format: html
autor: "Hicham Munir Tayfour"
editor: 
  markdown: 
    wrap: 72
---

O pacote DoubleML inclui os seguintes modelos.

## 3.1. Modelos Parcialmente Lineares (PLM)

Os modelos parcialmente lineares (PLM) assumem a forma

onde os efeitos do tratamento são aditivos com algum tipo de forma
linear.

### 3.1.1. Modelo de Regressão Parcialmente Linear (PLR)

Os modelos de regressão parcialmente linear (PLR) assumem a forma

$$Y = D\theta_0 + g_0(X) + \zeta, \quad \mathbb{E}[\zeta | D,X] = 0$$

$$D = m_0(X) + V, \quad \mathbb{E}[V | X] = 0$$

onde $Y$ é a variável de resultado e $D$ é a variável de política de
interesse. O vetor de alta dimensão $X$ consiste em outras covariáveis
confundidoras, e $\zeta$ e $V$ são erros estocásticos.

![Diagrama
causal](https://docs.doubleml.org/stable/_images/graphviz-8852e5db087f49410d0a5212d9b7fdcb58f0aaf9.png){fig-align="center"}

`DoubleMLPLR` implementa modelos PLR. A estimação é conduzida através do
seu método `fit()`.

::: callout-note
Observe que a abordagem padrão com `score='partialling out'` não se
baseia em uma estimativa direta de $\mathbb{E}[Y|X]$, mas
$\mathbb{E}[Y|D=0,X]$.
:::

```{r}
library(DoubleML)
library(mlr3)
library(mlr3learners)
library(data.table)
lgr::get_logger("mlr3")$set_threshold("warn")

learner = lrn("regr.ranger", num.trees = 100, mtry = 20, min.node.size = 2, max.depth = 5)
ml_l = learner$clone()
ml_m = learner$clone()
set.seed(1111)
data = make_plr_CCDDHNR2018(alpha=0.5, n_obs=500, dim_x=20, return_type='data.table')
obj_dml_data = DoubleMLData$new(data, y_col="y", d_cols="d")
dml_plr_obj = DoubleMLPLR$new(obj_dml_data, ml_l, ml_m)
dml_plr_obj$fit()
print(dml_plr_obj)
```

### 3.1.2. Modelo de Regressão IV Parcialmente Linear (PLIV)

Os modelos de regressão IV parcialmente linear (PLIV) assumem a forma

$$Y = D\theta_0 + g_0(X) + \zeta, \quad \mathbb{E}[\zeta | Z, X] = 0$$

$$Z = m_0(X) + V, \quad \mathbb{E}[V | X] = 0$$

$$D = r_0(X) + W, \quad \mathbb{E}[W | Z, X] = 0$$

onde $Y$ é a variável de resultado, $D$ é a variável de política de
interesse e $Z$ denota uma ou múltiplas variáveis instrumentais. O vetor
de alta dimensão $X$ consiste em outras covariáveis confundidoras, e
$\zeta$ e $V$ são erros estocásticos.

![Diagrama
causal](https://docs.doubleml.org/stable/_images/graphviz-21b721be23729673da52c6a08d58e43dd1769d11.png){fig-align="center"}

`DoubleMLPLIV` implementa modelos PLIV. A estimação é conduzida através
do seu método `fit()`:

```{r}
library(DoubleML)
library(mlr3)
library(mlr3learners)
library(data.table)

learner = lrn("regr.ranger", num.trees = 100, mtry = 20, min.node.size = 2, max.depth = 5)
ml_l = learner$clone()
ml_m = learner$clone()
ml_r = learner$clone()
set.seed(2222)
data = make_pliv_CHS2015(alpha=0.5, n_obs=500, dim_x=20, dim_z=1, return_type="data.table")
obj_dml_data = DoubleMLData$new(data, y_col="y", d_col = "d", z_cols= "Z1")
dml_pliv_obj = DoubleMLPLIV$new(obj_dml_data, ml_l, ml_m, ml_r)
dml_pliv_obj$fit()
print(dml_pliv_obj)
```

## 3.2. Modelos de Regressão Interativa (IRM)

O modelo de regressão interativa (IRM) assume a forma

onde os efeitos do tratamento são completamente heterogêneos.

### 3.2.1. Modelo de Regressão Interativa Binária (IRM)

Os modelos de regressão interativa (IRM) assumem a forma

$$Y = g_0(D, X) + U, \quad \mathbb{E}[U | X, D] = 0$$

$$D = m_0(X) + V, \quad \mathbb{E}[V | X] = 0$$

onde a variável de tratamento é binária, $D \in \{0,1\}$. Consideramos a
estimação dos efeitos médios do tratamento quando os efeitos do
tratamento são completamente heterogêneos.

Os parâmetros-alvo de interesse neste modelo são o efeito médio do
tratamento (ATE),

$$\theta_0 = \mathbb{E}[g_0(1, X) - g_0(0, X)]$$

e o efeito médio do tratamento sobre os tratados (ATTE),

$$\theta_0 = \mathbb{E}[g_0(1, X) - g_0(0, X) | D = 1]$$

![Diagrama
causal](https://docs.doubleml.org/stable/_images/graphviz-8852e5db087f49410d0a5212d9b7fdcb58f0aaf9.png){fig-align="center"}

`DoubleMLIRM` implementa modelos IRM. A estimação é conduzida através do
seu método `fit()`:

```{r}
library(DoubleML)
library(mlr3)
library(mlr3learners)
library(data.table)

set.seed(3333)
ml_g = lrn("regr.ranger", num.trees = 100, mtry = 10, min.node.size = 2, max.depth = 5)
ml_m = lrn("classif.ranger", num.trees = 100, mtry = 10, min.node.size = 2, max.depth = 5)
data = make_irm_data(theta=0.5, n_obs=500, dim_x=10, return_type="data.table")
obj_dml_data = DoubleMLData$new(data, y_col="y", d_cols="d")
dml_irm_obj = DoubleMLIRM$new(obj_dml_data, ml_g, ml_m)
dml_irm_obj$fit()
print(dml_irm_obj)
```

### 3.2.2. Resultados Potenciais Médios (APOs)

Para tratamentos discretos gerais $D \in \{d_0, d_1, \ldots, d_k\}$, o
modelo pode ser generalizado para

$$Y = \sum_{k=0}^K g_k(X) \mathbb{1}[D = d_k] + U, \quad \mathbb{E}[U|X,D] = 0$$

$$\mathbb{P}[D = d_k | X] = m_k(X), \quad D \perp U | X$$

onde $\mathbb{1}[D = d_k]$ é uma variável indicadora para o nível de
tratamento $d_k$ e $m_k(X)$ denota o escore de propensão correspondente.

Possíveis parâmetros-alvo de interesse neste modelo são os resultados
potenciais médios (APOs)

$$\theta_0(d_k) = \mathbb{E}[g_k(X)]$$

`DoubleMLAPO` implementa a estimação de resultados potenciais médios. A
estimação é conduzida através do seu método `fit()`:

::: callout-warning
**Nota**: A implementação de APO atualmente está disponível apenas em
Python no pacote DoubleML.
:::

### 3.2.3. Resultados Potenciais Médios (APOs) para Múltiplos Níveis de Tratamento

Se múltiplos níveis de tratamento devem ser estimados simultaneamente,
outro possível parâmetro-alvo de interesse neste modelo são os
contrastes (ou efeitos médios do tratamento) entre os níveis de
tratamento $d_j$ e $d_k$:

$$\Delta_{j,k} = \theta_0(d_j) - \theta_0(d_k)$$

`DoubleMLAPOS` implementa a estimação de resultados potenciais médios
para múltiplos níveis de tratamento. A estimação é conduzida através do
seu método `fit()`. O método `causal_contrast()` permite estimar
contrastes causais entre níveis de tratamento:

::: callout-warning
**Nota**: A implementação de APOS atualmente está disponível apenas em
Python no pacote DoubleML.
:::

### 3.2.4. Modelo IV Interativo (IIVM)

Os modelos de regressão IV interativa (IIVM) assumem a forma

$$Y = g_0(D, X) + U, \quad \mathbb{E}[U | Z, X] = 0$$

$$D = r_0(Z, X) + V, \quad \mathbb{E}[V | Z, X] = 0$$

$$Z = m_0(X) + \zeta, \quad \mathbb{E}[\zeta | X] = 0$$

onde a variável de tratamento é binária, $D \in \{0,1\}$ e o instrumento
é binário, $Z \in \{0,1\}$. Considere as funções $u_0(X)$, $r_0(1,X)$ e
$r_0(0,X)$, onde $u_0$ mapeia o suporte de $X$ para $\mathbb{R}$ e
$r_0(1,X)$ e $r_0(0,X)$ mapeiam respectivamente o suporte de $(1,X)$ e
$(0,X)$ para $\mathbb{R}$ para algum $\mathbb{R}$, tal que

$$Y = \theta_0 D + u_0(X) + U, \quad \mathbb{E}[U | Z, X] = 0$$

$$D = \mathbb{1}[Z \geq p_0(Z, X) + V], \quad \mathbb{E}[V | X] = 0$$

$$Z = m_0(X) + \zeta, \quad \mathbb{E}[\zeta | X] = 0$$

O parâmetro-alvo de interesse neste modelo é o efeito médio local do
tratamento (LATE),

$$\theta_0 = \mathbb{E}[Y(1) - Y(0) | M(1) = 1, M(0) = 0]$$

![Diagrama
causal](https://docs.doubleml.org/stable/_images/graphviz-21b721be23729673da52c6a08d58e43dd1769d11.png){fig-align="center"}

`DoubleMLIIVM` implementa modelos IIVM. A estimação é conduzida através
do seu método `fit()`:

```{r}
library(DoubleML)
library(mlr3)
library(mlr3learners)
library(data.table)

set.seed(4444)
ml_g = lrn("regr.ranger", num.trees = 100, mtry = 20, min.node.size = 2, max.depth = 5)
ml_m = lrn("classif.ranger", num.trees = 100, mtry = 20, min.node.size = 2, max.depth = 5)
ml_r = ml_m$clone()
data = make_iivm_data(theta=0.5, n_obs=1000, dim_x=20, alpha_x=1, return_type="data.table")
obj_dml_data = DoubleMLData$new(data, y_col="y", d_cols="d", z_cols="z")
dml_iivm_obj = DoubleMLIIVM$new(obj_dml_data, ml_g, ml_m, ml_r)
dml_iivm_obj$fit()
print(dml_iivm_obj)
```

## 3.3. Modelos de Diferenças-em-Diferenças (DID)

Os Modelos de Diferenças-em-Diferenças (DID) implementados no pacote
focam no caso de tratamento binário com adoção escalonada.

::: callout-note
A notação e as suposições de identificação são baseadas em Callaway e
Sant'Anna (2021), mas ajustadas para se adequar melhor às convenções
gerais da documentação do pacote, às vezes abusando ligeiramente da
notação. As funções de score subjacentes são baseadas em Sant'Anna e
Zhao (2020), Zimmert (2018) e Chang (2020). Para uma introdução mais
detalhada e desenvolvimentos recentes da literatura de
diferenças-em-diferenças, veja, por exemplo, Roth et al. (2022).
:::

Consideramos $N$ unidades observadas nos períodos de tempo
$t \in \{1, \ldots, T\}$. O status de tratamento para a unidade $i$ no
período de tempo $t$ é denotado pela variável binária $D_{it}$. O pacote
considera o cenário de adoção escalonada, onde uma unidade permanece
tratada após ter sido tratada uma vez (Irreversibilidade do Tratamento).

Seja $G_i$ uma variável indicadora que assume valor um se a unidade $i$
é tratada no período de tempo $G_i$, $G_i \in \{2, \ldots, T\}$ com
$G_i = 2$ referindo-se ao primeiro período pós-tratamento. Se as
unidades nunca são expostas ao tratamento, defina $G_i = \infty$.

Os parâmetros-alvo são definidos em termos de diferenças nos resultados
potenciais. O resultado observado e potencial para cada unidade $i$ no
período de tempo $t$ são assumidos como sendo da forma

$$Y_{it} = Y_{it}(0) + D_{it}(Y_{it}(1) - Y_{it}(0))$$

tal que observamos um resultado potencial consistente para cada unidade
em cada período de tempo.

Os parâmetros-alvo correspondentes são os efeitos causais médios do
tratamento

$$ATT(g,s,t) = \mathbb{E}[Y_t(g) - Y_t(0) | G = g]$$

Este parâmetro-alvo quantifica a mudança média nos resultados potenciais
para unidades que são tratadas pela primeira vez no período $g$, com a
diferença no resultado sendo avaliada para o período de tempo $t$. Os
grupos de controle correspondentes, definidos por um indicador $C$,
podem ser tipicamente definidos como as unidades nunca tratadas ou ainda
não tratadas. Seja

$$C^{nev} = \{i: G_i = \infty\}$$
$$C^{not,s} = \{i: D_{is} = 0, G_i \neq g\}$$
$$C^{not,t} = \{i: G_i > t\}$$

As suposições de identificação correspondentes são:

**Irreversibilidade do Tratamento:** Para todo $i \in \{1,\ldots,N\}$,
$D_{it} = 1$ implica $D_{is} = 1$ para todo $s > t$.

**Dados em Painel (Amostragem Aleatória):**
$\{Y_{it}(g), X_i, G_i\}_{i=1,\ldots,N;t=1,\ldots,T;g \in \mathcal{G}}$
é independente e identicamente distribuído.

**Antecipação Limitada do Tratamento:** Existe um $\delta \geq 0$
conhecido tal que $Y_{it}(G_i) = Y_{it}(0)$ para todo
$t \in \mathcal{T}$ tal que $t < G_i - \delta$.

**Tendências Paralelas Condicionais:** Seja $s = g - \delta - 1$ como
definido na Suposição 3. Para cada $g \in \mathcal{G}$ e
$t \in \mathcal{T}$ tal que $t \geq g - \delta$:

Nunca Tratados:
$$\mathbb{E}[Y_t(0) - Y_s(0) | X, G = g] = \mathbb{E}[Y_t(0) - Y_s(0) | X, C = 1]$$

Ainda Não Tratados:
$$\mathbb{E}[Y_t(0) - Y_s(0) | X, G = g] = \mathbb{E}[Y_t(0) - Y_s(0) | X, D_s = 0, G \neq g]$$

**Sobreposição:** Para cada período de tempo $g \in \mathcal{G}$ e
$t \in \mathcal{T}$ existe um $\epsilon > 0$ tal que
$\mathbb{P}[G = g | X] \geq \epsilon$ e
$\mathbb{P}[C = 1 | X] \geq \epsilon$.

::: callout-note
Para uma discussão detalhada das suposições, veja Callaway e Sant'Anna
(2021).
:::

Sob as suposições acima (Suposição 4.a ou 4.b), o parâmetro-alvo
$ATT(g,s,t)$ é identificado, veja Teorema 1. Callaway e Sant'Anna
(2021).

### 3.3.1. Dados em Painel

Para a estimação dos parâmetros-alvo $ATT(g,s,t)$, as seguintes funções
de nuisance são necessárias:

$$\mu_{g,C}(t,s,X) = \mathbb{E}[Y_t - Y_s | X, G = g, C = 1]$$
$$p_{g,C}(X) = \mathbb{P}[G = g | X, G \in \{g\} \cup C]$$

onde $\mu_{g,C}$ denota a função de regressão de resultado populacional
e $p_{g,C}$ o escore de propensão generalizado. A interpretação dos
parâmetros é a seguinte:

-   $g$ é o primeiro período pós-tratamento de interesse, isto é, o
    grupo de tratamento.
-   $s$ é o período pré-tratamento, isto é, o período de tempo a partir
    do qual as tendências paralelas condicionais são assumidas.
-   $t$ é o período de tempo de interesse ou período de avaliação, isto
    é, o período de tempo onde o efeito do tratamento é avaliado.
-   $\delta$ é o número de períodos de antecipação, isto é, o número de
    períodos de tempo para os quais se assume que as unidades antecipam
    o tratamento.

::: callout-note
Observe que as funções de nuisance dependem do grupo de controle usado
para a estimação do parâmetro-alvo. Por ligeiro abuso de notação, usamos
a mesma notação para ambos os grupos de controle $C^{nev}$ e
$C^{not,s}$. Mais especificamente, o grupo de controle depende apenas de
$s$ para unidades ainda não tratadas.
:::

Sob essas suposições, o parâmetro-alvo $ATT(g,s,t)$ pode ser estimado
escolhendo uma combinação adequada de $s < g - \delta$ se $t \geq g$,
isto é, as tendências paralelas são assumidas para manter pelo menos um
período a mais que o período de antecipação.

::: callout-note
A escolha $s = g - \delta - 1$ corresponde à definição de $ATT(g,t)$ de
Callaway e Sant'Anna (2021).
:::

Como exemplo, se o parâmetro-alvo é o efeito no grupo que recebe
tratamento em $g = 5$ mas avaliado em $t = 7$ com um período de
antecipação de $\delta = 0$, então o período pré-tratamento é $s = 4$. A
suposição de tendência paralela é ligeiramente mais forte com
antecipação, pois as tendências devem ser paralelas por períodos mais
longos, isto é, $t-s = 3 > g - s - \delta = 1$.

A seguir, omitiremos o subscrito $C$ na notação das funções de nuisance
e do grupo de controle (assumindo implicitamente $s < g - \delta$).

Para uma tupla dada $(g,s,t)$, o parâmetro-alvo $ATT(g,s,t)$ é estimado
resolvendo a versão empírica da seguinte condição de momento linear:

$$\mathbb{E}[\psi_{g,s,t}(W; \theta, \eta)] = 0$$

com elementos de nuisance $\eta = (\mu_g, p_g)$ e função de score $\psi$
sendo definida na seção Dados em Painel. Sob as suposições de
identificação acima

`DoubleMLDIDMulti` implementa a estimação de $ATT(g,s,t)$ para múltiplos
períodos de tempo e requer `DoubleMLPanelData` como entrada. Definir
`gt_combinations='standard'` estimará o parâmetro-alvo para todas as
combinações (possíveis) de $(g,s,t)$ com $g \in \{2, \ldots, T\}$ e
$t \in \{g, \ldots, T\}$ com $t \geq g$ e $s = g - \delta - 1$. Isso
corresponde ao cenário onde todas as tendências são definidas o mais
curto possível, mas ainda respeitando o período de antecipação.

A estimação é conduzida através do seu método `fit()`:

::: callout-warning
**Nota**: A implementação de DID Multi está atualmente disponível apenas
em Python no pacote DoubleML.
:::

### 3.3.2. Seções Transversais Repetidas

::: callout-note
Será implementado em breve.
:::

### 3.3.3. Agregação de Efeitos

A seção seguinte considera a agregação de diferentes $ATT(g,s,t)$ para
medidas resumidas baseadas em Callaway e Sant'Anna (2021). Todos os
esquemas de agregação implementados assumem a forma de uma média
ponderada das estimativas $ATT(g,s,t)$

$$\theta_W = \sum_{g \in \mathcal{G}} \sum_{s,t: g > s; t \geq g} w(g,s,t) \cdot ATT(g,s,t)$$

onde $w(g,s,t)$ é uma função de peso baseada no grupo de tratamento $g$
e período de tempo $t$. Os esquemas de agregação são implementados
através do método `aggregate()` da classe `DoubleMLDIDMulti`.

O método `aggregate()` requer que o argumento `aggregation` seja
definido como um dos seguintes valores:

-   **'group'**: agrega estimativas $ATT(g,s,t)$ pelo grupo de
    tratamento $g$.
-   **'time'**: agrega estimativas $ATT(g,s,t)$ pelo período de tempo
    $t$ (baseado no tamanho do grupo).
-   **'eventstudy'**: agrega estimativas $ATT(g,s,t)$ baseado na
    diferença de tempo para a primeira atribuição de tratamento como um
    estudo de evento (baseado no tamanho do grupo).
-   **dicionário**: um dicionário com valores contendo os pesos de
    agregação (como `numpy.ma.MaskedArray`).

::: callout-note
Um exemplo mais detalhado sobre agregação de efeitos está disponível na
galeria de exemplos. Para uma discussão detalhada sobre diferentes
esquemas de agregação, referimos a Callaway e Sant'Anna (2021).
:::

### 3.3.4. Dois Períodos de Tratamento

::: callout-warning
Esta documentação refere-se à implementação depreciada para dois
períodos de tempo. Esta funcionalidade será removida em uma versão
futura.
:::

::: callout-note
Recomendamos usar a implementação de Dados em Painel e Seções
Transversais Repetidas.
:::

Os Modelos de Diferenças-em-Diferenças (DID) implementados no pacote
focam no caso de tratamento binário com dois períodos de tratamento.

Adotando a notação de Sant'Anna e Zhao (2020), seja $Y_{it}$ o resultado
de interesse para a unidade $i$ no tempo $t$. Além disso, seja $D_i$
indicar se a unidade $i$ é tratada antes do tempo $t$ (caso contrário
$D_i = 0$). Como todas as unidades começam como não tratadas
($D_{i1} = 0$), defina $D_i = D_{i2}$. Baseando-se na notação de
resultado potencial, denote $Y_{it}(0)$ como o resultado da unidade $i$
no tempo $t$ se a unidade não recebeu tratamento até o tempo $t$ e
analogamente para $Y_{it}(1)$ com tratamento. Consequentemente, o
resultado observado para a unidade $i$ no tempo $t$ é
$Y_{it} = Y_{it}(D_i)$. Além disso, seja $X_i$ um vetor de covariáveis
pré-tratamento.

O parâmetro-alvo de interesse é o efeito médio do tratamento sobre os
tratados (ATTE)

$$\theta_0 = \mathbb{E}[Y_{i2}(1) - Y_{i2}(0) | D_i = 1]$$

As suposições de identificação correspondentes são

**(Cond.) Tendências Paralelas:**
$\mathbb{E}[Y_{i2}(0) - Y_{i1}(0) | D_i = 1, X_i] = \mathbb{E}[Y_{i2}(0) - Y_{i1}(0) | D_i = 0, X_i]$

**Sobreposição:** $\exists \epsilon > 0$:
$\epsilon \leq \mathbb{P}[D_i = 1 | X_i] \leq 1 - \epsilon$ e
$\mathbb{P}[D_i = 1] > 0$

::: callout-note
Para uma introdução mais detalhada e desenvolvimentos recentes da
literatura de diferenças-em-diferenças, veja, por exemplo, Roth et al.
(2022).
:::

#### 3.3.4.1. Dados em Painel

Se dados em painel estão disponíveis, as observações são assumidas como
sendo iid. da forma $(Y_{i1}, Y_{i2}, D_i, X_i)$. Observe que a
diferença $Y = Y_{i2} - Y_{i1}$ deve ser definida como o resultado `y`
no objeto `DoubleMLData`.

`DoubleMLDID` implementa modelos de diferenças-em-diferenças para dados
em painel. A estimação é conduzida através do seu método `fit()`:

::: callout-warning
**Nota**: A implementação de DID para dois períodos está atualmente
disponível apenas em Python no pacote DoubleML.
:::

#### 3.3.4.2. Seções Transversais Repetidas

Para seções transversais repetidas, as observações são assumidas como
sendo iid. da forma $(Y_i, D_i, T_i, X_i)$, onde $T_i$ é uma variável
dummy se a unidade $i$ é observada no período pré ou pós-tratamento, tal
que o resultado observado pode ser definido como

$$Y_i = T_i Y_{i2}(D_i) + (1 - T_i) Y_{i1}(0)$$

Além disso, tratamento e covariáveis são assumidos como estacionários,
tal que a distribuição conjunta de $(D_i, X_i)$ é invariante a $T_i$.

`DoubleMLDIDCS` implementa modelos de diferenças-em-diferenças para
seções transversais repetidas. A estimação é conduzida através do seu
método `fit()`:

::: callout-warning
**Nota**: A implementação de DIDCS está atualmente disponível apenas em
Python no pacote DoubleML.
:::

## 3.4. Modelos de Seleção Amostral (SSM)

Os Modelos de Seleção Amostral (SSM) implementados no pacote focam no
caso de tratamento binário quando os resultados são observados apenas
para uma subpopulação devido à seleção amostral ou atrito de resultados.

A implementação e notação são baseadas em Bia, Huber e Lafférs (2023).
Seja $D$ o indicador de tratamento binário e $Y(d)$ o resultado
potencial sob o valor de tratamento $d$. Além disso, defina
$Y = D Y(1) + (1-D) Y(0)$ como o resultado realizado e $S \in \{0,1\}$
como um indicador de seleção binária. O resultado $Y$ é observado apenas
se $S = 1$. Finalmente, seja $X$ um vetor de covariáveis observadas,
medidas antes da atribuição do tratamento.

O parâmetro-alvo de interesse é o efeito médio do tratamento (ATE)

$$\theta_0 = \mathbb{E}[Y(1) - Y(0)]$$

A suposição de identificação correspondente é

**Independência Condicional do Tratamento:** $(Y(0), Y(1)) \perp D | X$
para $\mathbb{P}$-q.t.p. $x$ no suporte de $X$

onde suposições adicionais são feitas no contexto do respectivo modelo
de seleção amostral.

::: callout-note
Um exemplo mais detalhado pode ser encontrado na Galeria de Exemplos.
:::

### 3.4.1. Falta Aleatória

Considere as duas suposições adicionais seguintes para o modelo de
seleção amostral:

**Independência Condicional da Seleção:** $Y(d) \perp S | D = d, X$ para
$d \in \{0,1\}$ e $\mathbb{P}$-q.t.p. $x$ no suporte de $X$

**Suporte Comum:** $\mathbb{P}[S = 1 | D = d, X = x] > 0$ e
$\mathbb{P}[D = d | S = 1, X = x] > 0$ para $d \in \{0,1\}$ e
$\mathbb{P}$-q.t.p. $x$ no suporte de $X$

tal que os resultados estão faltando aleatoriamente (para o score, veja
Scores).

`DoubleMLSSM` implementa modelos de seleção amostral. O score
`score='missing-at-random'` refere-se ao score correspondente baseado
nas suposições acima. O objeto `DoubleMLData` deve ser definido com o
argumento adicional `s_col` para o indicador de seleção. A estimação é
conduzida através do seu método `fit()`:

```{r}
library(DoubleML)
library(mlr3)
library(data.table)

set.seed(3141)
n_obs = 2000
df = make_ssm_data(n_obs=n_obs, mar=TRUE, return_type="data.table")
dml_data = DoubleMLData$new(df, y_col="y", d_cols="d", s_col="s")

ml_g = lrn("regr.cv_glmnet", nfolds = 5, s = "lambda.min")
ml_m = lrn("classif.cv_glmnet", nfolds = 5, s = "lambda.min")
ml_pi = lrn("classif.cv_glmnet", nfolds = 5, s = "lambda.min")

dml_ssm = DoubleMLSSM$new(dml_data, ml_g, ml_m, ml_pi, score="missing-at-random")
dml_ssm$fit()
print(dml_ssm)
```

### 3.4.2. Não-resposta Não Ignorável

Quando a seleção amostral ou atrito de resultados está relacionada a não
observáveis, a identificação geralmente requer um instrumento para o
indicador de seleção $S$. Considere as seguintes suposições adicionais
para a variável instrumental:

**Correlação Condicional:** $Cov(Z, S | D, X) \neq 0$

**Independência Condicional:** $Y(d) \perp Z | D = d, X$ e
$Z \perp D | X$ para $d \in \{0,1\}$ e $\mathbb{P}$-q.t.p. no suporte de
$(X,Z)$

Isso requer a variável instrumental $Z$, que não deve afetar $Y$ ou
estar associada a não observáveis afetando $Y$ condicional a $D$ e $X$.
Além disso, a seleção é determinada através de um modelo de limite
(desconhecido):

**Limite:** $S = \mathbb{1}[\pi(D, X, Z) \geq U_S]$ onde $\pi$ é uma
função geral e $U_S$ é um escalar com função de distribuição cumulativa
estritamente monótona condicional a $(D,X)$.

**Independência Condicional:** $U_S \perp Z | D, X$.

Seja $\pi(d,x,z) := \mathbb{P}[S = 1 | D = d, X = x, Z = z]$ denotar a
probabilidade de seleção. Adicionalmente, as seguintes suposições são
necessárias:

**Suporte Comum para Tratamento:**
$\mathbb{P}[D = d | S = 1, X = x] > 0$

**Homogeneidade de Efeito Condicional:** $Y(1) - Y(0) \perp Z | X$

**Suporte Comum para Seleção:**
$\mathbb{P}[0 < \pi(d, x, Z) < 1 | D = d, X = x, S = 1] = 1$ para
$d \in \{0,1\}$ e $\mathbb{P}$-q.t.p. no suporte de $X$

Para mais detalhes, veja Bia, Huber e Lafférs (2023).

![Caminhos causais sob não-resposta não
ignorável](https://docs.doubleml.org/stable/_images/py_ssm1.svg){fig-align="center"}

`DoubleMLSSM` implementa modelos de seleção amostral. O score
`score='nonignorable'` refere-se ao score correspondente baseado nas
suposições acima. O objeto `DoubleMLData` deve ser definido com o
argumento adicional `s_col` para o indicador de seleção e `z_cols` para
o instrumento. A estimação é conduzida através do seu método `fit()`:

```{r}
library(DoubleML)
library(mlr3)
library(data.table)

set.seed(3141)
n_obs = 2000
df = make_ssm_data(n_obs=n_obs, mar=FALSE, return_type="data.table")
dml_data = DoubleMLData$new(df, y_col="y", d_cols="d", z_cols = "z", s_col="s")

ml_g = lrn("regr.cv_glmnet", nfolds = 5, s = "lambda.min")
ml_m = lrn("classif.cv_glmnet", nfolds = 5, s = "lambda.min")
ml_pi = lrn("classif.cv_glmnet", nfolds = 5, s = "lambda.min")

dml_ssm = DoubleMLSSM$new(dml_data, ml_g, ml_m, ml_pi, score="nonignorable")
dml_ssm$fit()
print(dml_ssm)
```

## 3.5. Desenhos de Descontinuidade de Regressão (RDD)

Os Desenhos de Descontinuidade de Regressão (RDD) são métodos de
inferência causal usados quando a atribuição do tratamento é determinada
por uma variável contínua ("score") cruzando um limite conhecido
("cutoff"). Esses desenhos exploram descontinuidades na probabilidade de
receber tratamento no cutoff para estimar o efeito médio do tratamento.
Os RDDs são divididos em dois tipos principais: Sharp e Fuzzy.

A ideia-chave por trás do RDD é que as unidades logo acima e logo abaixo
do limite são assumidas como comparáveis, diferindo apenas na atribuição
do tratamento. Isso permite estimar o efeito causal no limite comparando
os resultados de unidades tratadas e não tratadas.

Nossa implementação segue o trabalho de Noack, Olma e Rothe (2024).

Seja $Y$ o resultado observado de um indivíduo e $D$ o tratamento que
recebeu. Usando um conjunto de covariáveis adicionais $X$ para cada
observação, $Y$ e $D$ podem ser ajustados em um primeiro estágio, para
reduzir o desvio padrão na estimação do efeito causal.

::: callout-note
Para se adequar à sintaxe do pacote, nossa notação difere da seguinte
forma daquela usada na maioria dos trabalhos padrão de RDD (como por
exemplo Cattaneo e Titiunik (2022)): - $S$ o score (em vez de $X$) - $X$
as covariáveis (em vez de $Z$) - $D$ o tratamento recebido (em RDD sharp
em vez de $T$) - $T$ o tratamento atribuído (relevante apenas em RDD
fuzzy)
:::

::: callout-note
O módulo doubleml.rdd depende de rdrobust que pode ser instalado via
`pip install rdrobust` ou `pip install doubleml[rdd]`.
:::

### 3.5.1. Desenho de Descontinuidade de Regressão Sharp

Em um RDD Sharp, o tratamento $D$ é deterministicamente atribuído no
cutoff ($D = \mathbb{1}[S \geq c]$).

Seja $S$ representar o score, e seja $c$ denotar o ponto de cutoff. Além
disso, seja $Y(1)$ e $Y(0)$ denotar os resultados potenciais com e sem
tratamento, respectivamente. Então, o efeito do tratamento no cutoff

$$\tau = \mathbb{E}[Y(1) - Y(0) | S = c]$$

é identificado como a diferença na expectativa condicional de $Y$ no
cutoff de ambos os lados

$$\tau = \lim_{s \downarrow c} \mathbb{E}[Y | S = s] - \lim_{s \uparrow c} \mathbb{E}[Y | S = s]$$

A suposição-chave para identificar este efeito em um RDD sharp é:

**Continuidade:** A média condicional dos resultados potenciais
$\mathbb{E}[Y(d) | S = s]$ para $d \in \{0,1\}$ é contínua no nível de
cutoff $s = c$.

Isso inclui a condição necessária de exogeneidade, implicando que as
unidades não podem manipular perfeitamente seu valor de $S$ para receber
ou evitar o tratamento exatamente no cutoff.

Sem o uso de covariáveis, $\tau$ é tipicamente estimado executando
regressões lineares locais separadas em cada lado do cutoff, produzindo
um estimador da forma:

$$\hat{\tau}_{SRD} = \sum_{i: S_i \geq c} w_i^+ Y_i - \sum_{i: S_i < c} w_i^- Y_i$$

onde os $w_i^{\pm}$ são pesos de regressão linear local que dependem dos
dados através das realizações da variável running apenas e $h$ é uma
largura de banda.

Sob condições padrão, que incluem que a variável running é continuamente
distribuída, e que a largura de banda $h$ tende a zero a uma taxa
apropriada, o estimador $\hat{\tau}_{SRD}$ é aproximadamente normalmente
distribuído em grandes amostras, com viés de ordem $h^2$ e variância de
ordem $1/(nh)$:

$$\hat{\tau}_{SRD} \approx N(\tau + h^2 B_{SRD}, V_{SRD}/(nh))$$

Se covariáveis estão disponíveis, elas podem ser usadas para melhorar a
precisão das estimativas empíricas de RD. A estratégia mais popular é
incluí-las linearmente e sem localização de kernel na regressão linear
local. Por álgebra simples de mínimos quadrados, este estimador de
"ajuste linear" pode ser escrito como um estimador sem covariáveis com o
resultado ajustado por covariáveis $\tilde{Y}_i$:

$$\hat{\tau}_{SRD,lin} = \sum_{i: S_i \geq c} w_i^+ \tilde{Y}_i - \sum_{i: S_i < c} w_i^- \tilde{Y}_i$$

Aqui, $\tilde{Y}_i = Y_i - X_i' \hat{\gamma}$ é o minimizador da
regressão

$$\hat{\gamma} = \arg\min_{\gamma \in \mathbb{R}^{d_X}} \sum_{i=1}^n K_h(S_i - c)(Y_i - \alpha_0^- - \alpha_1^-(S_i - c) - \beta D_i - X_i'\gamma)^2$$

com $K_h(u) = K(u/h)/h$ (veja fs_specification em Detalhes de
Implementação), $K_h(u) = K(u/h)/h$ com $K$ uma função kernel.

Se $\mathbb{E}[Y(d) | S = s]$ é duas vezes continuamente diferenciável
ao redor do cutoff, então a distribuição de $\hat{\tau}_{SRD,lin}$ é
similar à do estimador base com termo de variância potencialmente menor
$V_{SRD,lin}$.

Como este ajuste linear pode não explorar eficientemente a informação de
covariáveis disponível, o DoubleML apresenta um estimador RDD com ajuste
flexível de covariáveis baseado em funções de ajuste potencialmente não
lineares $\mu(d,x)$. O estimador assume a seguinte forma:

$$\hat{\tau}_{SRD,ML} = \sum_{i: S_i \geq c} w_i^+ (Y_i - \hat{\mu}(1, X_i)) - \sum_{i: S_i < c} w_i^- (Y_i - \hat{\mu}(0, X_i))$$

Similar a outros algoritmos no DoubleML, $\mu(d,x)$ é estimado por
métodos ML e com crossfitting. Diferente de outros modelos, não há score
ortogonal, mas uma propriedade de insensibilidade global similar se
mantém (para detalhes, veja Noack, Olma e Rothe (2024)). Ajustamos a
variável de resultado pela influência das covariáveis.

Isso reduz a variância na estimação potencialmente ainda mais para:

$$V_{SRD,ML} = f_c \cdot \bar{v}_c \cdot \kappa_2$$

com $\kappa_2$ sendo uma constante de kernel. Para maximizar a precisão
do estimador $\hat{\tau}_{SRD,ML}$ para qualquer largura de banda
particular $h$, $\mu(d,x)$ deve ser escolhido tal que $\bar{v}_c$ seja o
menor possível. A média igualmente ponderada dos limites esquerdo e
direito da função de expectativa condicional
$\mathbb{E}[Y | D = d, X = x, S = c]$ no cutoff alcança este objetivo.
De acordo com Noack, Olma e Rothe (2024), vale:

$$\mu^*(d,x) = \frac{1}{2}(\mu^+(d,x) + \mu^-(d,x))$$

onde:

$$\mu^{\pm}(d,x) = \lim_{s \to c^{\pm}} \mathbb{E}[Y | D = d, X = x, S = s]$$

`RDFlex` implementa este desenho de descontinuidade de regressão com
$\mu$ sendo estimado por métodos ML especificados pelo usuário. O
indicador `fuzzy=False` indica um desenho sharp. O objeto `DoubleMLData`
deve ser definido com os argumentos:

-   `y_col` refere-se ao resultado observado, sobre o qual queremos
    estimar o efeito no cutoff
-   `s_col` refere-se ao score
-   `x_cols` refere-se às covariáveis a serem ajustadas
-   `d_cols` é um indicador de se uma observação é tratada ou não. No
    desenho sharp, isso deve ser idêntico a um indicador de se uma
    observação está à esquerda ou à direita do cutoff
    ($D = \mathbb{1}[S \geq c]$)

A estimação é conduzida através do seu método `fit()`:

::: callout-warning
**Nota**: A implementação de RDD está atualmente disponível apenas em
Python no pacote DoubleML.
:::

### 3.5.2. Desenho de Descontinuidade de Regressão Fuzzy

Em um RDD Fuzzy, a atribuição do tratamento $T$ é idêntica ao RDD sharp
($T = \mathbb{1}[S \geq c]$), no entanto, a conformidade é limitada ao
redor do cutoff, o que leva a um tratamento recebido $D$ diferente do
atribuído ($D \neq T$) para algumas unidades.

O parâmetro de interesse no RDD Fuzzy é o efeito médio do tratamento no
cutoff, para todos os indivíduos que cumprem com a atribuição

$$\tau_{comply} = \mathbb{E}[Y(1) - Y(0) | \text{unit } i \text{ is complier}, S = c]$$

com $Y(d)$ sendo o resultado potencial sob os tratamentos potenciais.
Este efeito é identificado por

$$\tau_{comply} = \frac{\lim_{s \downarrow c} \mathbb{E}[Y | S = s] - \lim_{s \uparrow c} \mathbb{E}[Y | S = s]}{\lim_{s \downarrow c} \mathbb{E}[D | S = s] - \lim_{s \uparrow c} \mathbb{E}[D | S = s]}$$

As suposições para identificar o ATT em um RDD fuzzy são:

**Continuidade dos Resultados Potenciais:** Similar ao RDD sharp, a
média condicional dos resultados potenciais $\mathbb{E}[Y(d) | S = s]$
para $d \in \{0,1\}$ é contínua no nível de cutoff $s = c$.

**Continuidade da Probabilidade de Atribuição do Tratamento:** A
probabilidade de receber tratamento $\mathbb{P}[D = 1 | S = s]$ deve
mudar descontinuamente no cutoff, mas não deve haver outros saltos na
probabilidade.

**Monotonicidade:** Não deve haver "defiers", significando indivíduos
para os quais a atribuição do tratamento vai na direção oposta do score.

Sob considerações similares ao caso sharp, um estimador usando ajuste
flexível de covariáveis pode ser derivado como:

$$\hat{\tau}_{FRD,ML} = \frac{\sum_{i: S_i \geq c} w_i^+ (Y_i - \hat{\mu}_Y(1, X_i)) - \sum_{i: S_i < c} w_i^- (Y_i - \hat{\mu}_Y(0, X_i))}{\sum_{i: S_i \geq c} w_i^+ (D_i - \hat{\mu}_D(1, X_i)) - \sum_{i: S_i < c} w_i^- (D_i - \hat{\mu}_D(0, X_i))}$$

onde $\hat{\mu}_Y$ e $\hat{\mu}_D$ são definidos como no cenário RDD
sharp, com o resultado respectivo.

`RDFlex` implementa este RDD fuzzy com ajuste flexível de covariáveis. O
indicador `fuzzy=True` indica um desenho fuzzy. O objeto `DoubleMLData`
deve ser definido com os argumentos:

-   `y_col` refere-se ao resultado observado, sobre o qual queremos
    estimar o efeito no cutoff
-   `s_col` refere-se ao score
-   `x_cols` refere-se às covariáveis a serem ajustadas
-   `d_cols` é um indicador de se uma observação é tratada ou não. No
    desenho fuzzy, isso não deve ser idêntico a um indicador de se uma
    observação está à esquerda ou à direita do cutoff
    ($D \neq \mathbb{1}[S \geq c]$)

A estimação é conduzida através do seu método `fit()`:

::: callout-warning
**Nota**: A implementação de RDD Fuzzy está atualmente disponível apenas
em Python no pacote DoubleML.
:::

### 3.5.3. Detalhes de Implementação

Existem algumas especialidades na implementação do RDFlex que diferem do
resto do pacote e, portanto, merecem ser destacadas aqui.

**Seleção de Largura de Banda:** A largura de banda é um parâmetro de
ajuste crucial para algoritmos RDD. Por padrão, nossa implementação usa
o método `rdbwselect` da biblioteca rdrobust para uma seleção inicial.
Isso pode ser substituído pelo usuário usando o parâmetro `h_fs`. Como o
ajuste de covariáveis e o ajuste RDD estão interagindo, por padrão,
repetimos as etapas de seleção de largura de banda e estimação de
nuisance uma vez no método `fit()`. Isso pode ser ajustado por
`n_iterations`.

**Seleção de Kernel:** Outra decisão crucial ao estimar com RDD é o
kernel que determina os pesos para observações ao redor do cutoff. Para
isso, os parâmetros `fs_kernel` e `kernel` são importantes. O último é
um argumento-chave e é usado na estimação RDD, enquanto o `fs_kernel`
especifica o kernel usado na estimação de nuisance. Por padrão, ambos
são triangulares.

**Learners Locais e Globais:** O RDFlex estima as funções de nuisance
localmente ao redor do cutoff. Em certos cenários, pode ser desejável
realizar um ajuste global no suporte completo do score $S$. Para isso,
os Global Learners em `doubleml.utils` podem ser usados (veja nosso
notebook de exemplo na Galeria de Exemplos).

**Especificações do Primeiro Estágio:** Na estimação de nuisance, temos
que adicionar variável(is) para adicionar informações sobre a
localização da observação à esquerda ou à direita do cutoff. As opções
disponíveis são: No caso padrão `fs_specification="cutoff"`, isso é um
indicador de se a observação está à esquerda ou à direita. Se
`fs_specification="cutoff and score"`, adicionalmente o score é
adicionado. No caso de `fs_specification="interacted cutoff and score"`,
também um termo de interação do indicador de cutoff e o score é
adicionado.

**Efeitos de Intenção de Tratar:** Acima, demonstramos como estimar o
ATE no cutoff em um RDD fuzzy. Para estimar um efeito de Intenção de
Tratar em vez disso, o parâmetro `fuzzy=False` pode ser selecionado.

**Argumentos-chave:** rdrobust como a biblioteca RDD subjacente tem
parâmetros adicionais para ajustar a estimação. Você pode usar
`**kwargs` para adicioná-los via RDFlex.
